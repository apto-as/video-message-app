version: '3.8'

services:
  voicevox:
    image: voicevox/voicevox_engine:cpu-ubuntu20.04-latest
    container_name: voicevox_engine
    ports:
      - "50021:50021"
    networks:
      - voice_network
    restart: unless-stopped

  # OpenVoice service - DISABLED (replaced by qwen-tts for local inference)
  # To re-enable: remove profiles: [disabled] line
  openvoice:
    build:
      context: ./openvoice_native
      args:
        USE_CUDA: ${USE_CUDA:-false}
        DEVICE: ${DEVICE:-cpu}
    container_name: openvoice_native
    runtime: nvidia  # NVIDIA Container Runtime for GPU access
    ports:
      - "8001:8001"
    volumes:
      - ./data/backend/storage:/app/storage
      - ./openvoice_native/data/openvoice:/app/data/openvoice:ro
      - openvoice-tmp:/tmp  # 一時ファイル用の名前付きボリューム
    tmpfs:
      - /tmp/gradio:size=512M,mode=1777  # Gradio専用tmpfs（512MB制限、スティッキービット）
      - /tmp/tmpfiles_me:size=2G,mode=1777  # Whisper一時ファイル用tmpfs（2GB制限、スティッキービット）
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - DEVICE=${DEVICE:-cpu}
      - STORAGE_PATH=/app/storage
      - OPENVOICE_BASE_DIR=/app
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - voice_network
    restart: unless-stopped
    profiles:
      - disabled  # Service disabled - use qwen-tts instead

  # Qwen3 TTS Service - Local inference replacement for OpenVoice
  qwen-tts:
    build:
      context: ./qwen_tts_service
    container_name: qwen3_tts_service
    runtime: nvidia
    ports:
      - "8002:8002"
    volumes:
      - ./data/backend/storage:/app/storage
      - qwen3-models:/app/models
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - DEVICE=${DEVICE:-cuda}
      - STORAGE_PATH=/app/storage
      - LAZY_LOAD=true
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - voice_network
    restart: unless-stopped

  musetalk:
    build:
      context: ./musetalk_service
    container_name: musetalk_service
    runtime: nvidia  # NVIDIA Container Runtime for GPU access
    ports:
      - "8003:8003"
    volumes:
      - ./data/backend/storage:/app/storage
      - ./data/musetalk/models:/app/models
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - LAZY_LOAD=true
      - MAX_CONCURRENT_JOBS=2
      - CLEAR_CACHE_AFTER_GENERATION=true
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - voice_network
    restart: unless-stopped

  backend:
    build: ./backend
    container_name: voice_backend
    runtime: nvidia  # NVIDIA Container Runtime for GPU access (YOLO person detection)
    expose:
      - "55433"
    volumes:
      - ./data/backend/storage:/app/storage
      - ./backend:/app
    env_file:
      - ./backend/.env
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - ENVIRONMENT=docker
      - VOICEVOX_URL=http://voicevox:50021
      - QWEN_TTS_SERVICE_URL=http://qwen-tts:8002  # Qwen3-TTS voice cloning service
      - MUSETALK_SERVICE_URL=http://musetalk:8003  # MuseTalk lip-sync service
      - USE_LOCAL_TTS=true  # Use local Qwen3-TTS instead of OpenVoice
      - USE_LOCAL_LIPSYNC=true  # Use local MuseTalk instead of D-ID API
      - D_ID_API_KEY=${D_ID_API_KEY:-your-d-id-api-key-here}  # Fallback to D-ID if needed
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    networks:
      - voice_network
    depends_on:
      - voicevox
      - qwen-tts  # Changed from openvoice to qwen-tts for local inference
      - musetalk
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.production
    container_name: voice_frontend
    expose:
      - "80"
    networks:
      - voice_network
    depends_on:
      - backend
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    container_name: voice_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
      - ./ssl/server.crt:/etc/nginx/ssl/server.crt
      - ./ssl/server.key:/etc/nginx/ssl/server.key
    networks:
      - voice_network
    depends_on:
      - backend
      - frontend
    restart: unless-stopped

networks:
  voice_network:
    driver: bridge

volumes:
  openvoice-tmp:  # OpenVoice一時ファイル用ボリューム（自動削除）
  qwen3-models:   # Qwen3 TTS model cache volume
