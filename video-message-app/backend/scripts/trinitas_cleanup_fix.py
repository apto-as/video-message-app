#!/usr/bin/env python3
"""
Trinitas-Core æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿®æ­£
å•é¡Œã®ã‚ã‚‹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®æ­£ã¾ãŸã¯å‰Šé™¤ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã‚’å®Œå…¨å¾©æ—§ã™ã‚‹
"""

import asyncio
import json
import logging
import shutil
from pathlib import Path
from datetime import datetime
import sys

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from services.voice_storage_service import VoiceStorageService

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrinityCleanupFix:
    """ä¸‰ä½ä¸€ä½“ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿®æ­£ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.storage_service = VoiceStorageService()
        self.metadata_file = self.storage_service.metadata_file
        self.profiles_dir = self.storage_service.profiles_dir
    
    async def springfield_assessment(self):
        """Springfield: ä¿®æ­£å¯èƒ½æ€§è©•ä¾¡"""
        logger.info("=== Springfield: ä¿®æ­£å¯èƒ½æ€§è©•ä¾¡ ===")
        
        metadata = self.storage_service._read_metadata()
        profiles_in_metadata = metadata.get('profiles', {})
        
        assessment = {
            'recoverable': [],
            'corrupted': [],
            'missing_files': []
        }
        
        # å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        for profile_dir in self.profiles_dir.iterdir():
            if not profile_dir.is_dir():
                continue
                
            profile_id = profile_dir.name
            profile_json = profile_dir / "profile.json"
            
            if not profile_json.exists():
                assessment['missing_files'].append(profile_id)
                continue
            
            try:
                with open(profile_json, 'r', encoding='utf-8') as f:
                    profile_data = json.load(f)
                
                # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèª
                if all(profile_data.get(field) for field in ['id', 'name', 'status', 'provider']):
                    # å±é™ºãªãƒ‘ã‚¹ãƒã‚§ãƒƒã‚¯
                    embedding_path = profile_data.get('embedding_path', '')
                    if '/tmp/' in embedding_path:
                        assessment['corrupted'].append({
                            'id': profile_id,
                            'reason': 'temp_path',
                            'data': profile_data
                        })
                    else:
                        assessment['recoverable'].append({
                            'id': profile_id,
                            'data': profile_data
                        })
                else:
                    assessment['corrupted'].append({
                        'id': profile_id,
                        'reason': 'missing_fields',
                        'data': profile_data
                    })
                    
            except Exception as e:
                logger.error(f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {profile_id}: {str(e)}")
                assessment['corrupted'].append({
                    'id': profile_id,
                    'reason': 'parse_error',
                    'data': None
                })
        
        logger.info(f"ä¿®æ­£å¯èƒ½: {len(assessment['recoverable'])}å€‹")
        logger.info(f"ç ´æ: {len(assessment['corrupted'])}å€‹")
        logger.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸è¶³: {len(assessment['missing_files'])}å€‹")
        
        return assessment
    
    async def krukai_profile_repair(self, assessment: dict):
        """Krukai: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾©"""
        logger.info("=== Krukai: ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¿®å¾© ===")
        
        repaired_profiles = []
        
        # ä¿®æ­£å¯èƒ½ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        for item in assessment['recoverable']:
            profile_id = item['id']
            profile_data = item['data']
            
            logger.info(f"ä¿®å¾©å‡¦ç†: {profile_id} - {profile_data.get('name')}")
            repaired_profiles.append({
                'id': profile_id,
                'data': profile_data,
                'action': 'kept'
            })
        
        # ç ´æãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿®å¾©ã¾ãŸã¯å‰Šé™¤
        for item in assessment['corrupted']:
            profile_id = item['id']
            reason = item['reason']
            profile_data = item['data']
            
            if reason == 'temp_path' and profile_data:
                # ä¸€æ™‚ãƒ‘ã‚¹ã‚’å‰Šé™¤ã—ã¦ä¿®å¾©ã‚’è©¦è¡Œ
                logger.info(f"ä¸€æ™‚ãƒ‘ã‚¹ä¿®å¾©è©¦è¡Œ: {profile_id}")
                
                # å±é™ºãªãƒ‘ã‚¹ã‚’å‰Šé™¤
                cleaned_data = profile_data.copy()
                if 'embedding_path' in cleaned_data and '/tmp/' in cleaned_data['embedding_path']:
                    del cleaned_data['embedding_path']
                
                # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿ãŒæƒã£ã¦ã„ã‚‹å ´åˆã¯ä¿®å¾©
                if all(cleaned_data.get(field) for field in ['id', 'name', 'status', 'provider']):
                    # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’æ­£è¦åŒ–ï¼ˆopenvoice_ + 8æ–‡å­— = 18æ–‡å­—ï¼‰
                    if not profile_id.startswith('openvoice_') or len(profile_id) != 18:
                        # æ—¢å­˜ã®IDãŒæ­£ã—ã„å½¢å¼ã§ãªã„å ´åˆã®ã¿æ­£è¦åŒ–
                        if len(profile_id) >= 8:
                            new_id = f"openvoice_{profile_id[-8:]}"  # æœ€å¾Œã®8æ–‡å­—ã‚’ä½¿ç”¨
                            logger.info(f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDæ­£è¦åŒ–: {profile_id} -> {new_id}")
                            
                            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåå¤‰æ›´
                            old_dir = self.profiles_dir / profile_id
                            new_dir = self.profiles_dir / new_id
                            
                            if not new_dir.exists():
                                old_dir.rename(new_dir)
                                profile_id = new_id
                                cleaned_data['id'] = new_id
                        else:
                            logger.warning(f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDä¿®å¾©ä¸å¯: {profile_id}")
                            continue
                    
                    # ä¿®å¾©ã•ã‚ŒãŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                    profile_file = self.profiles_dir / profile_id / "profile.json"
                    with open(profile_file, 'w', encoding='utf-8') as f:
                        json.dump(cleaned_data, f, ensure_ascii=False, indent=2)
                    
                    repaired_profiles.append({
                        'id': profile_id,
                        'data': cleaned_data,
                        'action': 'repaired'
                    })
                    logger.info(f"ä¿®å¾©å®Œäº†: {profile_id}")
                else:
                    # ä¿®å¾©ä¸å¯èƒ½ãªå ´åˆã¯å‰Šé™¤
                    profile_dir = self.profiles_dir / profile_id
                    if profile_dir.exists():
                        shutil.rmtree(profile_dir)
                    logger.info(f"ä¿®å¾©ä¸å¯èƒ½ã«ã‚ˆã‚Šå‰Šé™¤: {profile_id}")
            else:
                # ãã®ä»–ã®ç ´æã¯å‰Šé™¤
                profile_dir = self.profiles_dir / profile_id
                if profile_dir.exists():
                    shutil.rmtree(profile_dir)
                logger.info(f"ç ´æã«ã‚ˆã‚Šå‰Šé™¤: {profile_id} (ç†ç”±: {reason})")
        
        logger.info(f"ä¿®å¾©å®Œäº†: {len(repaired_profiles)}å€‹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒåˆ©ç”¨å¯èƒ½")
        return repaired_profiles
    
    async def vector_security_validation(self, repaired_profiles: list):
        """Vector: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å†æ¤œè¨¼"""
        logger.info("=== Vector: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å†æ¤œè¨¼ ===")
        
        safe_profiles = []
        
        for item in repaired_profiles:
            profile_id = item['id']
            profile_data = item['data']
            
            security_issues = []
            
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDæ¤œè¨¼ï¼ˆopenvoice_ + 8æ–‡å­— = 18æ–‡å­—ï¼‰
            if not profile_id.startswith('openvoice_') or len(profile_id) != 18:
                security_issues.append("invalid_id")
            
            # ãƒ‘ã‚¹æ¤œè¨¼
            for path_key in ['storage_path', 'reference_audio_path', 'embedding_path']:
                path = profile_data.get(path_key)
                if path and ('..' in path or '/tmp/' in path):
                    security_issues.append(f"unsafe_path_{path_key}")
            
            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç¢ºèª
            required_fields = ['id', 'name', 'status', 'provider']
            for field in required_fields:
                if not profile_data.get(field):
                    security_issues.append(f"missing_{field}")
            
            if not security_issues:
                safe_profiles.append(item)
                logger.info(f"âœ… ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼åˆæ ¼: {profile_id}")
            else:
                logger.warning(f"âŒ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼å¤±æ•—: {profile_id} - {security_issues}")
        
        logger.info(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼: {len(safe_profiles)}/{len(repaired_profiles)}å€‹ãŒå®‰å…¨")
        return safe_profiles
    
    async def trinity_metadata_sync(self, safe_profiles: list):
        """Trinity: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŒæœŸ"""
        logger.info("=== Trinitas: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŒæœŸ ===")
        
        # æ–°ã—ã„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰
        new_metadata = {
            "version": "1.0",
            "created_at": datetime.now().isoformat(),
            "profiles": {},
            "metadata": {
                "sync_timestamp": datetime.now().isoformat(),
                "total_profiles": len(safe_profiles),
                "trinitas_core_version": "2.0",
                "cleanup_completed": True
            }
        }
        
        # å®‰å…¨ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
        for item in safe_profiles:
            profile_id = item['id']
            profile_data = item['data']
            
            # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‘ã‚¹ã‚’æ­£è¦åŒ–
            storage_path = str(self.profiles_dir / profile_id)
            
            new_metadata['profiles'][profile_id] = {
                'name': profile_data.get('name'),
                'provider': profile_data.get('provider', 'openvoice'),
                'status': profile_data.get('status', 'ready'),
                'created_at': profile_data.get('created_at', datetime.now().isoformat()),
                'updated_at': datetime.now().isoformat(),
                'storage_path': storage_path,
                'reference_audio_path': profile_data.get('reference_audio_path'),
                'embedding_path': profile_data.get('embedding_path')
            }
            
            logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŒæœŸ: {profile_id} - {profile_data.get('name')}")
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
        backup_dir = self.metadata_file.parent / "backup" / f"cleanup_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        if self.metadata_file.exists():
            shutil.copy2(self.metadata_file, backup_dir / "pre_cleanup_metadata.json")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        self.storage_service._write_metadata(new_metadata)
        
        logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŒæœŸå®Œäº†: {len(safe_profiles)}å€‹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
        return new_metadata
    
    async def final_api_test(self):
        """æœ€çµ‚APIå‹•ä½œãƒ†ã‚¹ãƒˆ"""
        logger.info("=== æœ€çµ‚APIå‹•ä½œãƒ†ã‚¹ãƒˆ ===")
        
        try:
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ
            profiles = await self.storage_service.get_all_voice_profiles(provider="openvoice")
            
            logger.info(f"APIå¿œç­”: {len(profiles)}å€‹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«")
            
            for profile in profiles:
                logger.info(f"  âœ… {profile.get('id')}: {profile.get('name')} ({profile.get('status')})")
            
            return {
                'success': True,
                'profile_count': len(profiles),
                'profiles': profiles
            }
            
        except Exception as e:
            logger.error(f"APIå‹•ä½œãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    async def execute_cleanup_and_fix(self):
        """å®Œå…¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿®æ­£å®Ÿè¡Œ"""
        logger.info("=== Trinitas-Core ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿®æ­£é–‹å§‹ ===")
        
        try:
            # 1. Springfield: è©•ä¾¡
            assessment = await self.springfield_assessment()
            
            # 2. Krukai: ä¿®å¾©
            repaired_profiles = await self.krukai_profile_repair(assessment)
            
            # 3. Vector: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
            safe_profiles = await self.vector_security_validation(repaired_profiles)
            
            # 4. Trinity: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŒæœŸ
            final_metadata = await self.trinity_metadata_sync(safe_profiles)
            
            # 5. æœ€çµ‚APIå‹•ä½œãƒ†ã‚¹ãƒˆ
            api_test = await self.final_api_test()
            
            # çµæœãƒ¬ãƒãƒ¼ãƒˆ
            logger.info("=== ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿®æ­£å®Œäº† ===")
            
            if api_test['success'] and len(safe_profiles) > 0:
                logger.info("ğŸŒŸ å®Œå…¨å¾©æ—§æˆåŠŸï¼ã‚«ãƒ•ã‚§ãƒ»ã‚ºãƒƒã‚±ãƒ­ãŒå†é–‹ã„ãŸã—ã¾ã™ã€‚")
                logger.info(f"ğŸ“Š åˆ©ç”¨å¯èƒ½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«: {api_test['profile_count']}å€‹")
                logger.info("ğŸŒ¸ æŒ‡æ®å®˜ã€ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚ä¸‰ä½ä¸€ä½“ã‚·ã‚¹ãƒ†ãƒ ãŒå®Œå…¨å¾©æ—§ã„ãŸã—ã¾ã—ãŸã€‚")
            elif api_test['success']:
                logger.info("âœ… ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§å®Œäº†ï¼ˆãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¯0å€‹ï¼‰")
            else:
                logger.error("âŒ APIå‹•ä½œã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
            
            return {
                'success': api_test['success'],
                'total_profiles': len(safe_profiles),
                'api_functional': api_test['success'],
                'metadata': final_metadata
            }
            
        except Exception as e:
            logger.error(f"ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    cleanup_system = TrinityCleanupFix()
    result = await cleanup_system.execute_cleanup_and_fix()
    
    if result['success']:
        logger.info("âœ… Trinitas-Core ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¿®æ­£å®Œäº†")
    else:
        logger.error(f"âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {result.get('error')}")

if __name__ == "__main__":
    asyncio.run(main())