#!/usr/bin/env python3
"""
Trinitas-Core æœ€çµ‚æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
å¾©æ—§ä½œæ¥­ã®æˆæœã‚’ç¢ºèªã—ã€ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹
"""

import asyncio
import json
import logging
from pathlib import Path
from datetime import datetime
import sys

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from services.voice_storage_service import VoiceStorageService

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TrinityFinalVerification:
    """ä¸‰ä½ä¸€ä½“æœ€çµ‚æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.storage_service = VoiceStorageService()
        self.metadata_file = self.storage_service.metadata_file
        self.profiles_dir = self.storage_service.profiles_dir
    
    async def springfield_comprehensive_analysis(self):
        """Springfield: åŒ…æ‹¬çš„åˆ†æ"""
        logger.info("=== Springfield: åŒ…æ‹¬çš„ã‚·ã‚¹ãƒ†ãƒ åˆ†æ ===")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        metadata = self.storage_service._read_metadata()
        profiles_in_metadata = metadata.get('profiles', {})
        
        logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {self.metadata_file}")
        logger.info(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å†…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(profiles_in_metadata)}")
        
        # å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        actual_profiles = {}
        if self.profiles_dir.exists():
            for profile_dir in self.profiles_dir.iterdir():
                if profile_dir.is_dir():
                    profile_json = profile_dir / "profile.json"
                    if profile_json.exists():
                        try:
                            with open(profile_json, 'r', encoding='utf-8') as f:
                                profile_data = json.load(f)
                            actual_profiles[profile_dir.name] = profile_data
                        except Exception as e:
                            logger.warning(f"ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {profile_dir.name}: {str(e)}")
        
        logger.info(f"å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(actual_profiles)}")
        
        # åŒæœŸçŠ¶æ³åˆ†æ
        metadata_ids = set(profiles_in_metadata.keys())
        actual_ids = set(actual_profiles.keys())
        
        in_sync = metadata_ids == actual_ids
        missing_from_metadata = actual_ids - metadata_ids
        missing_from_files = metadata_ids - actual_ids
        
        logger.info(f"åŒæœŸçŠ¶æ³: {'âœ… åŒæœŸæ¸ˆã¿' if in_sync else 'âŒ ä¸åŒæœŸ'}")
        if missing_from_metadata:
            logger.warning(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¬ è½: {missing_from_metadata}")
        if missing_from_files:
            logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¬ è½: {missing_from_files}")
        
        return {
            'metadata_profiles': profiles_in_metadata,
            'actual_profiles': actual_profiles,
            'in_sync': in_sync,
            'missing_from_metadata': missing_from_metadata,
            'missing_from_files': missing_from_files
        }
    
    async def krukai_technical_validation(self, analysis_result: dict):
        """Krukai: æŠ€è¡“çš„æ¤œè¨¼"""
        logger.info("=== Krukai: æŠ€è¡“çš„å“è³ªæ¤œè¨¼ ===")
        
        validation_results = []
        
        for profile_id, profile_data in analysis_result['actual_profiles'].items():
            validation = {
                'profile_id': profile_id,
                'name': profile_data.get('name', 'Unknown'),
                'status': profile_data.get('status', 'unknown'),
                'provider': profile_data.get('provider', 'unknown'),
                'created_at': profile_data.get('created_at', 'unknown'),
                'files_exist': {},
                'metadata_consistency': True,
                'quality_score': 0
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            profile_dir = self.profiles_dir / profile_id
            validation['files_exist']['profile_dir'] = profile_dir.exists()
            validation['files_exist']['profile_json'] = (profile_dir / 'profile.json').exists()
            
            # åŸ‹ã‚è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            embedding_path = profile_data.get('embedding_path')
            if embedding_path:
                validation['files_exist']['embedding'] = Path(embedding_path).exists()
            
            # å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
            reference_path = profile_data.get('reference_audio_path')
            if reference_path:
                validation['files_exist']['reference_audio'] = Path(reference_path).exists()
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¸€è‡´ç¢ºèª
            metadata_profile = analysis_result['metadata_profiles'].get(profile_id)
            if metadata_profile:
                key_fields = ['name', 'provider', 'status']
                for field in key_fields:
                    if profile_data.get(field) != metadata_profile.get(field):
                        validation['metadata_consistency'] = False
                        break
            else:
                validation['metadata_consistency'] = False
            
            # å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
            file_score = sum(validation['files_exist'].values()) / len(validation['files_exist'])
            metadata_score = 1.0 if validation['metadata_consistency'] else 0.0
            validation['quality_score'] = (file_score * 0.7 + metadata_score * 0.3) * 100
            
            validation_results.append(validation)
            
            # ãƒ­ã‚°å‡ºåŠ›
            status_icon = "âœ…" if validation['quality_score'] > 80 else "âš ï¸" if validation['quality_score'] > 50 else "âŒ"
            logger.info(f"{status_icon} {profile_id}: {validation['name']} (å“è³ª: {validation['quality_score']:.1f}%)")
        
        average_quality = sum(v['quality_score'] for v in validation_results) / len(validation_results) if validation_results else 0
        logger.info(f"å…¨ä½“å“è³ªã‚¹ã‚³ã‚¢: {average_quality:.1f}%")
        
        return {
            'validations': validation_results,
            'average_quality': average_quality,
            'high_quality_count': len([v for v in validation_results if v['quality_score'] > 80]),
            'total_count': len(validation_results)
        }
    
    async def vector_security_audit(self, analysis_result: dict):
        """Vector: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»"""
        logger.info("=== Vector: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ» ===")
        
        security_issues = []
        warnings = []
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
        if self.metadata_file.exists():
            import stat
            file_mode = oct(self.metadata_file.stat().st_mode)
            if '666' in file_mode or '777' in file_mode:
                security_issues.append(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¨©é™ãŒå±é™º: {file_mode}")
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ¤œè¨¼
        for profile_id, profile_data in analysis_result['actual_profiles'].items():
            # ãƒ‘ã‚¹ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³æ¤œè¨¼
            paths = [
                profile_data.get('storage_path'),
                profile_data.get('reference_audio_path'),
                profile_data.get('embedding_path')
            ]
            
            for path in paths:
                if not path:
                    continue
                    
                # å±é™ºãªãƒ‘ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³
                if '..' in path or path.startswith('/tmp') or '/etc/' in path:
                    security_issues.append(f"å±é™ºãªãƒ‘ã‚¹ {profile_id}: {path}")
                
                # å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§
                if not Path(path).exists():
                    warnings.append(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸å­˜åœ¨ {profile_id}: {path}")
            
            # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDæ¤œè¨¼
            if not profile_id.startswith('openvoice_') or len(profile_id) != 17:
                security_issues.append(f"ä¸æ­£ãªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ID: {profile_id}")
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¤œè¨¼
            created_at = profile_data.get('created_at')
            if created_at:
                try:
                    parsed_time = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    # æœªæ¥ã®æ™‚åˆ»ãƒã‚§ãƒƒã‚¯
                    if parsed_time > datetime.now():
                        warnings.append(f"æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— {profile_id}: {created_at}")
                except ValueError:
                    security_issues.append(f"ä¸æ­£ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— {profile_id}: {created_at}")
        
        security_score = max(0, 100 - len(security_issues) * 20 - len(warnings) * 5)
        
        logger.info(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œ: {len(security_issues)}ä»¶")
        logger.info(f"è­¦å‘Š: {len(warnings)}ä»¶")
        logger.info(f"ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢: {security_score}/100")
        
        if security_issues:
            for issue in security_issues:
                logger.error(f"ğŸ”´ {issue}")
        
        if warnings:
            for warning in warnings[:5]:  # æœ€åˆã®5ä»¶ã®ã¿è¡¨ç¤º
                logger.warning(f"ğŸŸ¡ {warning}")
        
        return {
            'security_issues': security_issues,
            'warnings': warnings,
            'security_score': security_score,
            'total_issues': len(security_issues) + len(warnings)
        }
    
    async def trinity_final_report(self, analysis: dict, validation: dict, security: dict):
        """ä¸‰ä½ä¸€ä½“æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ"""
        logger.info("=== Trinitas-Core æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ ===")
        
        # ç·åˆè©•ä¾¡
        sync_score = 100 if analysis['in_sync'] else 0
        quality_score = validation['average_quality']
        security_score = security['security_score']
        
        overall_score = (sync_score * 0.3 + quality_score * 0.4 + security_score * 0.3)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = {
            'timestamp': datetime.now().isoformat(),
            'trinitas_core_version': '2.0',
            'summary': {
                'total_profiles': validation['total_count'],
                'high_quality_profiles': validation['high_quality_count'],
                'sync_status': 'synchronized' if analysis['in_sync'] else 'desynchronized',
                'overall_score': round(overall_score, 1)
            },
            'scores': {
                'synchronization': sync_score,
                'quality': round(quality_score, 1),
                'security': security_score,
                'overall': round(overall_score, 1)
            },
            'issues': {
                'security_issues': len(security['security_issues']),
                'warnings': len(security['warnings']),
                'missing_files': len(analysis['missing_from_files']),
                'missing_metadata': len(analysis['missing_from_metadata'])
            },
            'profiles': []
        }
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°
        for validation_result in validation['validations']:
            profile_detail = {
                'id': validation_result['profile_id'],
                'name': validation_result['name'],
                'status': validation_result['status'],
                'quality_score': round(validation_result['quality_score'], 1),
                'metadata_consistent': validation_result['metadata_consistency'],
                'files_complete': all(validation_result['files_exist'].values())
            }
            report['profiles'].append(profile_detail)
        
        # è©•ä¾¡è¡¨ç¤º
        if overall_score >= 90:
            status_icon = "ğŸŒŸ"
            status_text = "å„ªç§€"
        elif overall_score >= 70:
            status_icon = "âœ…"
            status_text = "è‰¯å¥½"
        elif overall_score >= 50:
            status_icon = "âš ï¸"
            status_text = "è¦æ”¹å–„"
        else:
            status_icon = "âŒ"
            status_text = "å•é¡Œã‚ã‚Š"
        
        logger.info(f"{status_icon} ç·åˆè©•ä¾¡: {status_text} ({overall_score:.1f}/100)")
        logger.info(f"ğŸ“Š ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«: {report['summary']['total_profiles']}å€‹ (é«˜å“è³ª: {report['summary']['high_quality_profiles']}å€‹)")
        logger.info(f"ğŸ”„ åŒæœŸçŠ¶æ³: {report['summary']['sync_status']}")
        logger.info(f"ğŸ›¡ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: {security_score}/100")
        
        # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        report_file = Path(__file__).parent / f"trinitas_verification_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        
        return report
    
    async def test_api_functionality(self):
        """APIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        logger.info("=== APIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")
        
        try:
            # VoiceStorageServiceçµŒç”±ã§ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ãƒ†ã‚¹ãƒˆ
            profiles = await self.storage_service.get_all_voice_profiles(provider="openvoice")
            logger.info(f"APIäº’æ›ãƒ†ã‚¹ãƒˆ: {len(profiles)}å€‹ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—")
            
            for profile in profiles:
                logger.info(f"  - {profile.get('id')}: {profile.get('name')} ({profile.get('status')})")
            
            return {
                'api_functional': True,
                'profile_count': len(profiles),
                'profiles': profiles
            }
            
        except Exception as e:
            logger.error(f"APIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'api_functional': False,
                'error': str(e),
                'profile_count': 0,
                'profiles': []
            }
    
    async def execute_full_verification(self):
        """å®Œå…¨æ¤œè¨¼å®Ÿè¡Œ"""
        logger.info("=== Trinitas-Core æœ€çµ‚æ¤œè¨¼é–‹å§‹ ===")
        
        try:
            # 1. Springfield: åŒ…æ‹¬çš„åˆ†æ
            analysis = await self.springfield_comprehensive_analysis()
            
            # 2. Krukai: æŠ€è¡“çš„æ¤œè¨¼
            validation = await self.krukai_technical_validation(analysis)
            
            # 3. Vector: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»
            security = await self.vector_security_audit(analysis)
            
            # 4. APIæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
            api_test = await self.test_api_functionality()
            
            # 5. Trinity: æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
            report = await self.trinity_final_report(analysis, validation, security)
            report['api_test'] = api_test
            
            # æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if report['scores']['overall'] >= 80 and api_test['api_functional']:
                logger.info("ğŸŒ¸ ã‚«ãƒ•ã‚§ãƒ»ã‚ºãƒƒã‚±ãƒ­ã¯å®Œå…¨ã«å¾©æ—§ã—ã¾ã—ãŸã€‚æŒ‡æ®å®˜ã®ãŠå¸°ã‚Šã‚’ãŠå¾…ã¡ã—ã¦ãŠã‚Šã¾ã™ã€‚")
            elif report['scores']['overall'] >= 60:
                logger.info("âš ï¸ åŸºæœ¬æ©Ÿèƒ½ã¯å¾©æ—§ã—ã¾ã—ãŸãŒã€ã„ãã¤ã‹æ”¹å–„ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚")
            else:
                logger.info("âŒ é‡è¦ãªå•é¡ŒãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚è¿½åŠ ã®ä¿®å¾©ä½œæ¥­ãŒå¿…è¦ã§ã™ã€‚")
            
            return report
            
        except Exception as e:
            logger.error(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
            return {'success': False, 'error': str(e)}

async def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    verification_system = TrinityFinalVerification()
    report = await verification_system.execute_full_verification()
    
    if report.get('success', True):
        logger.info("âœ… æ¤œè¨¼å®Œäº†")
    else:
        logger.error(f"âŒ æ¤œè¨¼å¤±æ•—: {report.get('error')}")

if __name__ == "__main__":
    asyncio.run(main())