# AWS MCPçµ±åˆå¾Œã®å…¨ä½“ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸

**Version**: 2.0.0-AWS-MCP
**Date**: 2025-11-02
**Status**: Design Proposal
**Author**: Athena (Trinitas Harmonious Conductor)

---

## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

æœ¬è¨­è¨ˆæ›¸ã¯ã€Video Message Appã®æ—¢å­˜ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«AWS MCP Serverã€æ–°ç”»åƒå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆBiRefNet/SAM2ï¼‰ã€ãƒ—ãƒ­ã‚½ãƒ‡ã‚£èª¿æ•´ã‚¨ãƒ³ã‚¸ãƒ³ã€BGMåˆæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã™ã‚‹ãŸã‚ã®åŒ…æ‹¬çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¤‰æ›´ã‚’å®šç¾©ã—ã¾ã™ã€‚

### ä¸»è¦ãªè¨­è¨ˆæ±ºå®š

1. **ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–**: ãƒ¢ãƒãƒªã‚·ãƒƒã‚¯ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‹ã‚‰6ã¤ã®å°‚é–€åŒ–ã‚µãƒ¼ãƒ“ã‚¹ã¸åˆ†é›¢
2. **éåŒæœŸå‡¦ç†**: Celery + Redis ã«ã‚ˆã‚‹é‡ã„å‡¦ç†ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
3. **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: ãƒ­ãƒ¼ã‚«ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆé–‹ç™ºï¼‰+ S3ï¼ˆæœ¬ç•ªï¼‰ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
4. **æ®µéšçš„ç§»è¡Œ**: æ—¢å­˜æ©Ÿèƒ½ã‚’å£Šã•ãšã«æ–°æ©Ÿèƒ½ã‚’è¿½åŠ ï¼ˆStrangler Fig Patternï¼‰

---

## 2. çµ±åˆå¾Œã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

### 2.1 å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³

```mermaid
graph TB
    subgraph "Client Layer"
        FE[React Frontend<br/>Port 55434]
    end

    subgraph "API Gateway Layer"
        NGINX[Nginx Reverse Proxy<br/>Port 80/443]
    end

    subgraph "Application Services (Docker)"
        API[API Gateway Service<br/>FastAPI - Port 55433]
        VOICE[Voice Service<br/>Port 55440]
        IMAGE[Image Processing Service<br/>BiRefNet/SAM2<br/>Port 55441]
        PROSODY[Prosody Adjustment Service<br/>Port 55442]
        BGM[BGM Synthesis Service<br/>Port 55443]
        VIDEO[Video Generation Service<br/>D-ID Integration<br/>Port 55444]
    end

    subgraph "Infrastructure Services (Docker)"
        REDIS[(Redis Cache<br/>Port 6379)]
        CELERY[Celery Workers<br/>Async Queue]
        FLOWER[Flower Monitor<br/>Port 5555]
    end

    subgraph "External Services (Native)"
        VOICEVOX[VOICEVOX Engine<br/>Docker - Port 50021]
        OPENVOICE[OpenVoice Native<br/>Mac Conda - Port 8001]
        AWS_MCP[AWS MCP Server<br/>uvx managed]
    end

    subgraph "External APIs"
        DID[D-ID API<br/>Video Generation]
        S3[AWS S3<br/>Storage]
        BEDROCK[AWS Bedrock<br/>AI Models]
    end

    subgraph "Storage Layer"
        LOCAL[Local Storage<br/>./data/backend/storage]
        S3_BUCKET[S3 Bucket<br/>video-message-app-prod]
    end

    FE -->|REST API| NGINX
    NGINX -->|/api/*| API

    API -->|Voice Synthesis| VOICE
    API -->|Image Processing| IMAGE
    API -->|Prosody Adjustment| PROSODY
    API -->|BGM Synthesis| BGM
    API -->|Video Generation| VIDEO

    VOICE -->|TTS| VOICEVOX
    VOICE -->|Clone| OPENVOICE
    VOICE -.->|Queue| CELERY

    IMAGE -->|Background Removal| AWS_MCP
    IMAGE -->|Segmentation| AWS_MCP
    IMAGE -.->|Queue| CELERY

    PROSODY -.->|Queue| CELERY
    BGM -.->|Queue| CELERY

    VIDEO -->|Generate| DID
    VIDEO -.->|Queue| CELERY

    CELERY -->|State| REDIS
    CELERY -->|Monitor| FLOWER

    VOICE -->|Read/Write| LOCAL
    IMAGE -->|Read/Write| LOCAL
    VIDEO -->|Read/Write| LOCAL

    AWS_MCP -->|Storage| S3
    AWS_MCP -->|AI| BEDROCK

    IMAGE -->|Production| S3_BUCKET
    VIDEO -->|Production| S3_BUCKET
```

### 2.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³ï¼ˆE2E Processing Pipelineï¼‰

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API_GW as API Gateway
    participant Redis
    participant Celery
    participant ImageSvc as Image Service
    participant AWS_MCP
    participant VoiceSvc as Voice Service
    participant OpenVoice
    participant ProsodySvc as Prosody Service
    participant BGMSvc as BGM Service
    participant VideoSvc as Video Service
    participant DID as D-ID API
    participant S3

    User->>Frontend: Upload Image + Text
    Frontend->>API_GW: POST /api/video/generate

    API_GW->>Redis: Create Task ID
    API_GW->>Celery: Queue: image_processing
    API_GW-->>Frontend: 202 Accepted {task_id}

    Note over Celery,ImageSvc: Phase 1: Image Processing (Async)
    Celery->>ImageSvc: Process Image Task
    ImageSvc->>AWS_MCP: BiRefNet Background Removal
    AWS_MCP-->>ImageSvc: Segmented Image
    ImageSvc->>AWS_MCP: SAM2 Refinement
    AWS_MCP-->>ImageSvc: Refined Mask
    ImageSvc->>S3: Upload Processed Image
    ImageSvc->>Redis: Update Task Status: image_ready
    ImageSvc->>Celery: Queue: voice_synthesis

    Note over Celery,VoiceSvc: Phase 2: Voice Synthesis (Async)
    Celery->>VoiceSvc: Synthesize Voice Task
    VoiceSvc->>OpenVoice: Clone Voice (if profile)
    OpenVoice-->>VoiceSvc: Audio WAV
    VoiceSvc->>ProsodySvc: Adjust Prosody
    ProsodySvc-->>VoiceSvc: Enhanced Audio
    VoiceSvc->>S3: Upload Audio
    VoiceSvc->>Redis: Update Task Status: voice_ready
    VoiceSvc->>Celery: Queue: bgm_synthesis

    Note over Celery,BGMSvc: Phase 3: BGM Synthesis (Async)
    Celery->>BGMSvc: Add BGM Task
    BGMSvc->>BGMSvc: Mix Voice + BGM
    BGMSvc->>S3: Upload Final Audio
    BGMSvc->>Redis: Update Task Status: audio_ready
    BGMSvc->>Celery: Queue: video_generation

    Note over Celery,VideoSvc: Phase 4: Video Generation (Async)
    Celery->>VideoSvc: Generate Video Task
    VideoSvc->>S3: Download Image + Audio
    VideoSvc->>DID: Create Talking Avatar
    DID-->>VideoSvc: Video URL
    VideoSvc->>S3: Upload Final Video
    VideoSvc->>Redis: Update Task Status: completed

    Frontend->>API_GW: GET /api/video/status/{task_id}
    API_GW->>Redis: Get Task Status
    Redis-->>API_GW: Status: completed, video_url
    API_GW-->>Frontend: 200 OK {video_url}
    Frontend->>S3: Download Video
    S3-->>User: Video Playback
```

---

## 3. ã‚µãƒ¼ãƒ“ã‚¹è©³ç´°è¨­è¨ˆ

### 3.1 API Gateway Service (Port 55433)

**è²¬å‹™**:
- ã™ã¹ã¦ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
- èªè¨¼ãƒ»èªå¯ï¼ˆå°†æ¥çš„ã«JWTï¼‰
- ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨è² è·åˆ†æ•£
- ã‚¿ã‚¹ã‚¯ç®¡ç†ã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¿½è·¡

**ä¸»è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**:
```python
# æ—¢å­˜ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
POST   /api/voices/synthesize          # VOICEVOXåˆæˆ
POST   /api/voice-clone/create         # ã‚¯ãƒ­ãƒ¼ãƒ³ä½œæˆ
POST   /api/voice-clone/synthesize     # ã‚¯ãƒ­ãƒ¼ãƒ³åˆæˆ
POST   /api/d-id/generate-video        # D-IDå‹•ç”»ç”Ÿæˆ

# æ–°è¦ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆçµ±åˆï¼‰
POST   /api/video/generate             # E2Eå‹•ç”»ç”Ÿæˆï¼ˆéåŒæœŸï¼‰
GET    /api/video/status/{task_id}     # ã‚¿ã‚¹ã‚¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
GET    /api/video/download/{task_id}   # å‹•ç”»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
POST   /api/image/process              # ç”»åƒå‡¦ç†ã®ã¿
POST   /api/audio/prosody              # ãƒ—ãƒ­ã‚½ãƒ‡ã‚£èª¿æ•´ã®ã¿
POST   /api/audio/bgm                  # BGMåˆæˆã®ã¿
```

**ç’°å¢ƒå¤‰æ•°**:
```bash
# Service Discovery
VOICE_SERVICE_URL=http://voice-service:55440
IMAGE_SERVICE_URL=http://image-service:55441
PROSODY_SERVICE_URL=http://prosody-service:55442
BGM_SERVICE_URL=http://bgm-service:55443
VIDEO_SERVICE_URL=http://video-service:55444

# Async Queue
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/1

# Storage (Environment-aware)
STORAGE_BACKEND=local|s3
AWS_REGION=us-west-2
S3_BUCKET_NAME=video-message-app-prod
```

---

### 3.2 Voice Service (Port 55440)

**è²¬å‹™**:
- VOICEVOXæ—¥æœ¬èªTTS
- OpenVoiceéŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³
- ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ï¼ˆCRUDï¼‰
- éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç®¡ç†

**ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**:
- `VoiceVoxClient` (æ—¢å­˜)
- `OpenVoiceNativeClient` (æ—¢å­˜)
- `VoiceStorageService` (æ—¢å­˜)
- `VoiceProfileManager` (æ–°è¦ - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†)

**Dockerfile** (`services/voice-service/Dockerfile`):
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY . .

# Expose port
EXPOSE 55440

# Run service
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "55440"]
```

**API Contract**:
```yaml
POST /synthesize:
  body:
    text: string
    voice_type: "voicevox" | "openvoice"
    profile_id: string (optional)
    language: string (default: "ja")
  response:
    audio_url: string
    duration: float
    format: "wav"

POST /voice-clone/create:
  body:
    name: string
    audio_samples: file[] (max 5)
    language: string
  response:
    profile_id: string
    embedding_path: string

GET /voice-clone/profiles:
  response:
    profiles:
      - id: string
        name: string
        language: string
        created_at: datetime
```

---

### 3.3 Image Processing Service (Port 55441)

**è²¬å‹™**:
- BiRefNetã«ã‚ˆã‚‹èƒŒæ™¯é™¤å»
- SAM2ã«ã‚ˆã‚‹é«˜ç²¾åº¦ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- ç”»åƒãƒªã‚µã‚¤ã‚ºãƒ»ã‚¯ãƒ­ãƒƒãƒ—
- AWS MCP Serveré€£æº

**æ–°è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**:
```python
# services/image-service/processors/birefnet_processor.py
class BiRefNetProcessor:
    """BiRefNet background removal using AWS MCP"""

    async def remove_background(
        self,
        image_path: str,
        output_path: str
    ) -> dict:
        """Remove background from image"""
        # AWS MCPçµŒç”±ã§BiRefNetå®Ÿè¡Œ
        result = await self.aws_mcp_client.invoke_bedrock(
            model="birefnet-v2",
            input_image=image_path,
            task="background_removal"
        )

        # S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœ¬ç•ªç’°å¢ƒï¼‰
        if settings.storage_backend == "s3":
            await self.s3_client.upload(
                result['output_image'],
                output_path
            )

        return result

# services/image-service/processors/sam2_processor.py
class SAM2Processor:
    """SAM2 segmentation refinement using AWS MCP"""

    async def refine_segmentation(
        self,
        image_path: str,
        mask_path: str,
        output_path: str
    ) -> dict:
        """Refine segmentation with SAM2"""
        result = await self.aws_mcp_client.invoke_bedrock(
            model="sam2-large",
            input_image=image_path,
            input_mask=mask_path,
            task="segmentation_refinement"
        )

        return result
```

**Dockerfile** (`services/image-service/Dockerfile`):
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies for image processing
RUN apt-get update && apt-get install -y \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install AWS MCP Server (uvx managed)
RUN pip install uvx
RUN uvx --from mcp install mcp-server-aws

COPY . .

EXPOSE 55441

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "55441"]
```

**requirements.txt**:
```
fastapi==0.104.1
uvicorn[standard]==0.24.0
opencv-python==4.8.1
pillow==10.1.0
numpy<2.0
boto3==1.29.7  # AWS S3 client
httpx==0.25.1  # AWS MCP communication
celery==5.3.4
redis==5.0.1
```

---

### 3.4 Prosody Adjustment Service (Port 55442)

**è²¬å‹™**:
- éŸ³å£°ã®éŸ»å¾‹èª¿æ•´ï¼ˆãƒ”ãƒƒãƒã€é€Ÿåº¦ã€å¼·å¼±ï¼‰
- æ„Ÿæƒ…è¡¨ç¾ã®å¼·åŒ–
- è‡ªç„¶ãªé–“ï¼ˆãƒãƒ¼ã‚ºï¼‰ã®æŒ¿å…¥

**æ–°è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**:
```python
# services/prosody-service/adjusters/prosody_adjuster.py
import librosa
import soundfile as sf
import numpy as np

class ProsodyAdjuster:
    """Prosody adjustment engine"""

    async def adjust_prosody(
        self,
        audio_path: str,
        output_path: str,
        params: dict
    ) -> dict:
        """
        Adjust prosody of audio file

        Args:
            audio_path: Input audio file
            output_path: Output audio file
            params:
                pitch_shift: float (-12 to 12 semitones)
                time_stretch: float (0.5 to 2.0)
                energy_boost: float (0.5 to 1.5)
                emotion: str ("neutral", "happy", "sad", "angry")
        """
        # Load audio
        y, sr = librosa.load(audio_path, sr=None)

        # Pitch shift
        if params.get('pitch_shift', 0) != 0:
            y = librosa.effects.pitch_shift(
                y, sr=sr,
                n_steps=params['pitch_shift']
            )

        # Time stretch
        if params.get('time_stretch', 1.0) != 1.0:
            y = librosa.effects.time_stretch(
                y,
                rate=params['time_stretch']
            )

        # Energy adjustment
        if params.get('energy_boost', 1.0) != 1.0:
            y = y * params['energy_boost']

        # Emotion-based adjustments
        if params.get('emotion') == 'happy':
            y = self._apply_happy_prosody(y, sr)
        elif params.get('emotion') == 'sad':
            y = self._apply_sad_prosody(y, sr)

        # Save output
        sf.write(output_path, y, sr)

        return {
            'output_path': output_path,
            'duration': len(y) / sr,
            'sample_rate': sr
        }

    def _apply_happy_prosody(self, y, sr):
        """Apply happy emotion prosody (higher pitch, faster)"""
        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=2)
        y = librosa.effects.time_stretch(y, rate=1.1)
        return y

    def _apply_sad_prosody(self, y, sr):
        """Apply sad emotion prosody (lower pitch, slower)"""
        y = librosa.effects.pitch_shift(y, sr=sr, n_steps=-2)
        y = librosa.effects.time_stretch(y, rate=0.9)
        return y
```

**Dockerfile**:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install audio processing dependencies
RUN apt-get update && apt-get install -y \
    libsndfile1 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 55442

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "55442"]
```

**requirements.txt**:
```
fastapi==0.104.1
uvicorn[standard]==0.24.0
librosa==0.10.1
soundfile==0.12.1
numpy<2.0
celery==5.3.4
redis==5.0.1
```

---

### 3.5 BGM Synthesis Service (Port 55443)

**è²¬å‹™**:
- éŸ³å£°ã¨BGMã®ãƒŸã‚­ã‚·ãƒ³ã‚°
- éŸ³é‡ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
- BGMãƒ©ã‚¤ãƒ–ãƒ©ãƒªç®¡ç†

**æ–°è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**:
```python
# services/bgm-service/mixers/audio_mixer.py
from pydub import AudioSegment
import os

class AudioMixer:
    """Audio mixing engine for voice + BGM"""

    BGM_LIBRARY = {
        'calm': 'bgm/calm_piano.mp3',
        'upbeat': 'bgm/upbeat_acoustic.mp3',
        'corporate': 'bgm/corporate_motivational.mp3',
        'emotional': 'bgm/emotional_strings.mp3'
    }

    async def mix_audio(
        self,
        voice_path: str,
        output_path: str,
        bgm_type: str = 'calm',
        bgm_volume: float = 0.3
    ) -> dict:
        """
        Mix voice with BGM

        Args:
            voice_path: Voice audio file
            output_path: Output mixed audio
            bgm_type: Type of BGM (calm, upbeat, corporate, emotional)
            bgm_volume: BGM volume (0.0 to 1.0, voice is always 1.0)
        """
        # Load voice
        voice = AudioSegment.from_file(voice_path)
        voice_duration = len(voice)

        # Load BGM
        bgm_path = self.BGM_LIBRARY.get(bgm_type, 'bgm/calm_piano.mp3')
        bgm = AudioSegment.from_file(bgm_path)

        # Loop BGM to match voice duration
        if len(bgm) < voice_duration:
            loops = (voice_duration // len(bgm)) + 1
            bgm = bgm * loops

        # Trim BGM to voice duration
        bgm = bgm[:voice_duration]

        # Adjust BGM volume
        bgm = bgm - (20 * (1 - bgm_volume))  # Reduce volume in dB

        # Mix (overlay)
        mixed = voice.overlay(bgm)

        # Normalize to prevent clipping
        mixed = mixed.normalize()

        # Export
        mixed.export(output_path, format='mp3', bitrate='192k')

        return {
            'output_path': output_path,
            'duration': len(mixed) / 1000.0,  # in seconds
            'format': 'mp3'
        }
```

**Dockerfile**:
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install audio dependencies
RUN apt-get update && apt-get install -y \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy BGM library
COPY bgm/ /app/bgm/

COPY . .

EXPOSE 55443

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "55443"]
```

**requirements.txt**:
```
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydub==0.25.1
celery==5.3.4
redis==5.0.1
```

---

### 3.6 Video Generation Service (Port 55444)

**è²¬å‹™**:
- D-ID APIé€£æºï¼ˆæ—¢å­˜æ©Ÿèƒ½ç¶­æŒï¼‰
- S3ã‹ã‚‰ã®ç”»åƒãƒ»éŸ³å£°å–å¾—
- å‹•ç”»ç”Ÿæˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¿½è·¡
- å®Œæˆå‹•ç”»ã®S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

**æ—¢å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå¼·åŒ–**:
```python
# services/video-service/clients/d_id_client.py (æ—¢å­˜ã‚’æ‹¡å¼µ)
from clients.storage_client import StorageClient

class DIDClientEnhanced:
    """Enhanced D-ID client with storage integration"""

    def __init__(self):
        self.storage = StorageClient()  # S3 or Local
        self.did_api_key = os.getenv('D_ID_API_KEY')
        self.base_url = 'https://api.d-id.com'

    async def generate_video_from_storage(
        self,
        image_key: str,
        audio_key: str,
        output_key: str
    ) -> dict:
        """
        Generate video using files from storage

        Args:
            image_key: S3 key or local path for image
            audio_key: S3 key or local path for audio
            output_key: S3 key or local path for output video
        """
        # Download from storage if S3
        image_url = await self.storage.get_presigned_url(image_key)
        audio_url = await self.storage.get_presigned_url(audio_key)

        # Call D-ID API
        response = await self._call_did_api(image_url, audio_url)

        # Poll for completion
        video_url = await self._poll_did_status(response['id'])

        # Download and upload to storage
        video_data = await self._download_video(video_url)
        await self.storage.upload(output_key, video_data)

        return {
            'video_url': await self.storage.get_presigned_url(output_key),
            'did_id': response['id']
        }
```

---

## 4. éåŒæœŸå‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆCeleryï¼‰

### 4.1 Celeryã‚¿ã‚¹ã‚¯è¨­è¨ˆ

```python
# tasks/video_generation_pipeline.py
from celery import chain, group
from tasks import (
    process_image_task,
    synthesize_voice_task,
    adjust_prosody_task,
    add_bgm_task,
    generate_video_task
)

@celery_app.task(bind=True)
def generate_video_pipeline(self, request_data: dict):
    """
    E2E video generation pipeline

    Pipeline:
    1. Image Processing (BiRefNet + SAM2)
    2. Voice Synthesis (VOICEVOX or OpenVoice)
    3. Prosody Adjustment
    4. BGM Synthesis
    5. Video Generation (D-ID)
    """
    task_id = self.request.id

    # Update status
    update_task_status(task_id, 'processing', 'Starting pipeline')

    # Chain tasks
    pipeline = chain(
        process_image_task.s(request_data['image']),
        synthesize_voice_task.s(request_data['text'], request_data.get('voice_profile')),
        adjust_prosody_task.s(request_data.get('prosody_params', {})),
        add_bgm_task.s(request_data.get('bgm_type', 'calm')),
        generate_video_task.s(request_data['image'])
    )

    result = pipeline.apply_async()

    return {
        'task_id': task_id,
        'status': 'queued',
        'pipeline_id': result.id
    }

# Individual tasks
@celery_app.task
def process_image_task(image_data: dict):
    """Step 1: Process image with BiRefNet + SAM2"""
    client = ImageServiceClient()
    result = await client.process_image(
        image_data['path'],
        steps=['background_removal', 'sam2_refinement']
    )
    return result

@celery_app.task
def synthesize_voice_task(previous_result: dict, text: str, profile_id: str = None):
    """Step 2: Synthesize voice"""
    client = VoiceServiceClient()
    result = await client.synthesize(text, profile_id)
    return {**previous_result, 'audio_path': result['audio_url']}

@celery_app.task
def adjust_prosody_task(previous_result: dict, prosody_params: dict):
    """Step 3: Adjust prosody"""
    client = ProsodyServiceClient()
    result = await client.adjust(
        previous_result['audio_path'],
        prosody_params
    )
    return {**previous_result, 'audio_path': result['output_path']}

@celery_app.task
def add_bgm_task(previous_result: dict, bgm_type: str):
    """Step 4: Add BGM"""
    client = BGMServiceClient()
    result = await client.mix(
        previous_result['audio_path'],
        bgm_type
    )
    return {**previous_result, 'audio_path': result['output_path']}

@celery_app.task
def generate_video_task(previous_result: dict, image_data: dict):
    """Step 5: Generate video with D-ID"""
    client = VideoServiceClient()
    result = await client.generate(
        image_path=previous_result['image_path'],
        audio_path=previous_result['audio_path']
    )
    return {**previous_result, 'video_url': result['video_url']}
```

### 4.2 Celeryè¨­å®š

```python
# celery_config.py
from celery import Celery

celery_app = Celery(
    'video_message_app',
    broker='redis://redis:6379/0',
    backend='redis://redis:6379/1'
)

celery_app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='Asia/Tokyo',
    enable_utc=True,
    task_track_started=True,
    task_time_limit=1800,  # 30 minutes
    task_soft_time_limit=1500,  # 25 minutes
    worker_prefetch_multiplier=1,  # For long-running tasks
    worker_max_tasks_per_child=10,  # Memory leak prevention
)

# Task routing
celery_app.conf.task_routes = {
    'tasks.process_image_task': {'queue': 'image_processing'},
    'tasks.synthesize_voice_task': {'queue': 'voice_synthesis'},
    'tasks.adjust_prosody_task': {'queue': 'audio_processing'},
    'tasks.add_bgm_task': {'queue': 'audio_processing'},
    'tasks.generate_video_task': {'queue': 'video_generation'},
}
```

---

## 5. ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æˆ¦ç•¥

### 5.1 çµ±ä¸€ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

```python
# storage/storage_client.py
from abc import ABC, abstractmethod
from typing import Optional
import os
import boto3
from pathlib import Path

class StorageBackend(ABC):
    """Abstract storage backend"""

    @abstractmethod
    async def upload(self, key: str, data: bytes) -> str:
        """Upload file and return URL"""
        pass

    @abstractmethod
    async def download(self, key: str) -> bytes:
        """Download file data"""
        pass

    @abstractmethod
    async def get_url(self, key: str) -> str:
        """Get accessible URL"""
        pass

    @abstractmethod
    async def delete(self, key: str) -> bool:
        """Delete file"""
        pass

class LocalStorageBackend(StorageBackend):
    """Local filesystem storage (development)"""

    def __init__(self, base_path: str = '/app/storage'):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

    async def upload(self, key: str, data: bytes) -> str:
        file_path = self.base_path / key
        file_path.parent.mkdir(parents=True, exist_ok=True)

        async with aiofiles.open(file_path, 'wb') as f:
            await f.write(data)

        return f'file://{file_path}'

    async def download(self, key: str) -> bytes:
        file_path = self.base_path / key
        async with aiofiles.open(file_path, 'rb') as f:
            return await f.read()

    async def get_url(self, key: str) -> str:
        return f'file://{self.base_path / key}'

    async def delete(self, key: str) -> bool:
        file_path = self.base_path / key
        if file_path.exists():
            file_path.unlink()
            return True
        return False

class S3StorageBackend(StorageBackend):
    """AWS S3 storage (production)"""

    def __init__(self, bucket_name: str, region: str = 'us-west-2'):
        self.bucket_name = bucket_name
        self.region = region
        self.s3_client = boto3.client('s3', region_name=region)

    async def upload(self, key: str, data: bytes) -> str:
        """Upload to S3 with public-read ACL"""
        self.s3_client.put_object(
            Bucket=self.bucket_name,
            Key=key,
            Body=data,
            ACL='public-read'
        )
        return f'https://{self.bucket_name}.s3.{self.region}.amazonaws.com/{key}'

    async def download(self, key: str) -> bytes:
        response = self.s3_client.get_object(
            Bucket=self.bucket_name,
            Key=key
        )
        return response['Body'].read()

    async def get_url(self, key: str) -> str:
        """Get presigned URL (valid for 1 hour)"""
        return self.s3_client.generate_presigned_url(
            'get_object',
            Params={'Bucket': self.bucket_name, 'Key': key},
            ExpiresIn=3600
        )

    async def delete(self, key: str) -> bool:
        self.s3_client.delete_object(
            Bucket=self.bucket_name,
            Key=key
        )
        return True

class StorageClient:
    """Unified storage client with environment detection"""

    def __init__(self):
        backend_type = os.getenv('STORAGE_BACKEND', 'local')

        if backend_type == 's3':
            bucket_name = os.getenv('S3_BUCKET_NAME', 'video-message-app-prod')
            region = os.getenv('AWS_REGION', 'us-west-2')
            self.backend = S3StorageBackend(bucket_name, region)
        else:
            base_path = os.getenv('STORAGE_ROOT_PATH', '/app/storage')
            self.backend = LocalStorageBackend(base_path)

    async def upload(self, key: str, data: bytes) -> str:
        return await self.backend.upload(key, data)

    async def download(self, key: str) -> bytes:
        return await self.backend.download(key)

    async def get_url(self, key: str) -> str:
        return await self.backend.get_url(key)

    async def delete(self, key: str) -> bool:
        return await self.backend.delete(key)
```

### 5.2 ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# Usage in services
from storage.storage_client import StorageClient

async def process_video_generation(image_file, audio_file):
    storage = StorageClient()

    # Upload input files
    image_key = f'inputs/images/{uuid.uuid4()}.png'
    audio_key = f'inputs/audio/{uuid.uuid4()}.mp3'

    image_url = await storage.upload(image_key, image_file.read())
    audio_url = await storage.upload(audio_key, audio_file.read())

    # Process...
    video_data = await generate_video(image_url, audio_url)

    # Upload output
    video_key = f'outputs/videos/{uuid.uuid4()}.mp4'
    video_url = await storage.upload(video_key, video_data)

    return video_url
```

---

## 6. ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ï¼ˆRedisï¼‰

### 6.1 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼è¨­è¨ˆ

```python
# cache/cache_client.py
import redis.asyncio as redis
import json
from typing import Optional, Any
import hashlib

class CacheClient:
    """Redis cache client"""

    def __init__(self, redis_url: str = 'redis://redis:6379/2'):
        self.redis = redis.from_url(redis_url, decode_responses=True)

    async def get(self, key: str) -> Optional[Any]:
        """Get cached value"""
        value = await self.redis.get(key)
        if value:
            return json.loads(value)
        return None

    async def set(self, key: str, value: Any, ttl: int = 3600):
        """Set cached value with TTL (default 1 hour)"""
        await self.redis.setex(
            key,
            ttl,
            json.dumps(value)
        )

    async def delete(self, key: str):
        """Delete cached value"""
        await self.redis.delete(key)

    async def get_or_compute(
        self,
        key: str,
        compute_fn,
        ttl: int = 3600
    ):
        """Get from cache or compute and cache"""
        cached = await self.get(key)
        if cached is not None:
            return cached

        # Compute
        value = await compute_fn()
        await self.set(key, value, ttl)
        return value

    @staticmethod
    def make_key(*args, **kwargs) -> str:
        """Generate cache key from arguments"""
        key_parts = [str(arg) for arg in args]
        key_parts.extend(f'{k}={v}' for k, v in sorted(kwargs.items()))
        key_string = ':'.join(key_parts)
        return hashlib.md5(key_string.encode()).hexdigest()

# Usage examples
cache = CacheClient()

# Cache voice profiles
async def get_voice_profiles():
    return await cache.get_or_compute(
        'voice_profiles:all',
        lambda: voice_service.list_profiles(),
        ttl=300  # 5 minutes
    )

# Cache processed images
async def get_processed_image(image_id: str):
    cache_key = f'processed_image:{image_id}'
    return await cache.get_or_compute(
        cache_key,
        lambda: image_service.process(image_id),
        ttl=1800  # 30 minutes
    )
```

### 6.2 ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾è±¡

| ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥ | TTL | ç†ç”± |
|-----------|-----|------|
| Voice Profiles | 5åˆ† | é »ç¹ã«å¤‰æ›´ã•ã‚Œãªã„ãŒã€æ–°è¦ä½œæˆæ™‚ã¯ã™ãåæ˜  |
| Processed Images | 30åˆ† | é‡ã„å‡¦ç†ã€åŒã˜ç”»åƒã®å†å‡¦ç†ã‚’é˜²ã |
| BGM Metadata | 1æ™‚é–“ | é™çš„ãƒ‡ãƒ¼ã‚¿ |
| D-ID Video Status | 1åˆ† | ãƒãƒ¼ãƒªãƒ³ã‚°é »åº¦åˆ¶å¾¡ |
| Task Status | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  | Celeryãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ç®¡ç† |

---

## 7. ç’°å¢ƒåˆ¥æ§‹æˆç®¡ç†

### 7.1 é–‹ç™ºç’°å¢ƒï¼ˆLocalï¼‰

**docker-compose.dev.yml**:
```yaml
version: '3.8'

services:
  # Existing services
  voicevox:
    image: voicevox/voicevox_engine:cpu-ubuntu20.04-latest
    ports:
      - "50021:50021"
    networks:
      - voice_network

  # New microservices
  api-gateway:
    build: ./services/api-gateway
    ports:
      - "55433:55433"
    environment:
      - ENVIRONMENT=development
      - STORAGE_BACKEND=local
      - STORAGE_ROOT_PATH=/app/storage
      - CELERY_BROKER_URL=redis://redis:6379/0
      - VOICE_SERVICE_URL=http://voice-service:55440
      - IMAGE_SERVICE_URL=http://image-service:55441
      - PROSODY_SERVICE_URL=http://prosody-service:55442
      - BGM_SERVICE_URL=http://bgm-service:55443
      - VIDEO_SERVICE_URL=http://video-service:55444
    volumes:
      - ./data/backend/storage:/app/storage
      - ./services/api-gateway:/app
    networks:
      - voice_network
    depends_on:
      - redis
      - voice-service

  voice-service:
    build: ./services/voice-service
    ports:
      - "55440:55440"
    environment:
      - VOICEVOX_URL=http://voicevox:50021
      - OPENVOICE_SERVICE_URL=http://host.docker.internal:8001
      - STORAGE_BACKEND=local
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./data/backend/storage:/app/storage
    networks:
      - voice_network

  image-service:
    build: ./services/image-service
    ports:
      - "55441:55441"
    environment:
      - STORAGE_BACKEND=local
      - AWS_MCP_ENDPOINT=http://localhost:8000  # MCP Server
    volumes:
      - ./data/backend/storage:/app/storage
    networks:
      - voice_network

  prosody-service:
    build: ./services/prosody-service
    ports:
      - "55442:55442"
    environment:
      - STORAGE_BACKEND=local
    volumes:
      - ./data/backend/storage:/app/storage
    networks:
      - voice_network

  bgm-service:
    build: ./services/bgm-service
    ports:
      - "55443:55443"
    environment:
      - STORAGE_BACKEND=local
    volumes:
      - ./data/backend/storage:/app/storage
      - ./bgm:/app/bgm  # BGM library
    networks:
      - voice_network

  video-service:
    build: ./services/video-service
    ports:
      - "55444:55444"
    environment:
      - D_ID_API_KEY=${D_ID_API_KEY}
      - STORAGE_BACKEND=local
    volumes:
      - ./data/backend/storage:/app/storage
    networks:
      - voice_network

  # Infrastructure
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - voice_network

  celery-worker:
    build: ./services/celery-worker
    command: celery -A tasks worker --loglevel=info --concurrency=2
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    volumes:
      - ./data/backend/storage:/app/storage
    networks:
      - voice_network
    depends_on:
      - redis

  flower:
    build: ./services/celery-worker
    command: celery -A tasks flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
    networks:
      - voice_network
    depends_on:
      - redis

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "55434:3000"
    environment:
      - REACT_APP_API_URL=http://localhost:55433
    volumes:
      - ./frontend:/app
      - /app/node_modules
    networks:
      - voice_network

networks:
  voice_network:
    driver: bridge
```

### 7.2 æœ¬ç•ªç’°å¢ƒï¼ˆAWS EC2 + S3ï¼‰

**docker-compose.prod.yml**:
```yaml
version: '3.8'

services:
  api-gateway:
    build: ./services/api-gateway
    expose:
      - "55433"
    environment:
      - ENVIRONMENT=production
      - STORAGE_BACKEND=s3
      - S3_BUCKET_NAME=video-message-app-prod
      - AWS_REGION=us-west-2
      - CELERY_BROKER_URL=redis://redis:6379/0
      - VOICE_SERVICE_URL=http://voice-service:55440
      - IMAGE_SERVICE_URL=http://image-service:55441
      - PROSODY_SERVICE_URL=http://prosody-service:55442
      - BGM_SERVICE_URL=http://bgm-service:55443
      - VIDEO_SERVICE_URL=http://video-service:55444
    networks:
      - voice_network
    restart: unless-stopped

  voice-service:
    build: ./services/voice-service
    expose:
      - "55440"
    environment:
      - VOICEVOX_URL=http://voicevox:50021
      - OPENVOICE_SERVICE_URL=http://localhost:8001  # EC2 local
      - STORAGE_BACKEND=s3
      - S3_BUCKET_NAME=video-message-app-prod
    networks:
      - voice_network
    restart: unless-stopped

  image-service:
    build: ./services/image-service
    expose:
      - "55441"
    environment:
      - STORAGE_BACKEND=s3
      - S3_BUCKET_NAME=video-message-app-prod
      - AWS_MCP_ENDPOINT=http://localhost:8000
    networks:
      - voice_network
    restart: unless-stopped

  # ... (other services similar pattern)

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
      - ./ssl/letsencrypt:/etc/nginx/ssl
    networks:
      - voice_network
    depends_on:
      - api-gateway
      - frontend
    restart: unless-stopped

  celery-worker:
    build: ./services/celery-worker
    command: celery -A tasks worker --loglevel=info --concurrency=4
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/1
      - STORAGE_BACKEND=s3
      - S3_BUCKET_NAME=video-message-app-prod
    networks:
      - voice_network
    restart: unless-stopped
    deploy:
      replicas: 2  # Scale workers

networks:
  voice_network:
    driver: bridge
```

### 7.3 ç’°å¢ƒå¤‰æ•°ç®¡ç†

**.env.development**:
```bash
# Environment
ENVIRONMENT=development

# Storage
STORAGE_BACKEND=local
STORAGE_ROOT_PATH=/app/storage

# Services
VOICEVOX_URL=http://voicevox:50021
OPENVOICE_SERVICE_URL=http://host.docker.internal:8001

# D-ID
D_ID_API_KEY=your_dev_key_here

# Logging
LOG_LEVEL=DEBUG
```

**.env.production**:
```bash
# Environment
ENVIRONMENT=production

# Storage
STORAGE_BACKEND=s3
S3_BUCKET_NAME=video-message-app-prod
AWS_REGION=us-west-2

# Services
VOICEVOX_URL=http://voicevox:50021
OPENVOICE_SERVICE_URL=http://localhost:8001

# D-ID
D_ID_API_KEY=your_prod_key_here

# Logging
LOG_LEVEL=INFO

# AWS MCP
AWS_MCP_ENDPOINT=http://localhost:8000
```

---

## 8. éšœå®³æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥

### 8.1 ã‚µãƒ¼ãƒ“ã‚¹éšœå®³å¯¾å¿œ

```python
# services/api-gateway/fallback/service_fallback.py
import httpx
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class ServiceCircuitBreaker:
    """Circuit breaker for service calls"""

    def __init__(self, service_name: str, failure_threshold: int = 5):
        self.service_name = service_name
        self.failure_threshold = failure_threshold
        self.failure_count = 0
        self.is_open = False

    async def call(self, fn, *args, **kwargs):
        """Call service with circuit breaker"""
        if self.is_open:
            logger.warning(f'Circuit breaker OPEN for {self.service_name}')
            raise ServiceUnavailableError(f'{self.service_name} is unavailable')

        try:
            result = await fn(*args, **kwargs)
            self.failure_count = 0  # Reset on success
            return result
        except Exception as e:
            self.failure_count += 1
            logger.error(f'{self.service_name} call failed: {e}')

            if self.failure_count >= self.failure_threshold:
                self.is_open = True
                logger.error(f'Circuit breaker OPENED for {self.service_name}')

            raise

class ServiceFallback:
    """Fallback strategies for each service"""

    @staticmethod
    async def voice_synthesis_fallback(text: str) -> bytes:
        """Fallback to VOICEVOX if OpenVoice fails"""
        logger.info('Using VOICEVOX fallback for voice synthesis')
        voicevox_client = VoiceVoxClient()
        return await voicevox_client.synthesize(text, speaker_id=1)

    @staticmethod
    async def image_processing_fallback(image_path: str) -> dict:
        """Fallback to simple background removal if AWS MCP fails"""
        logger.info('Using simple background removal fallback')
        # Use local rembg library
        from rembg import remove
        with open(image_path, 'rb') as f:
            input_data = f.read()
        output_data = remove(input_data)

        # Save to storage
        storage = StorageClient()
        output_key = f'processed/{uuid.uuid4()}.png'
        await storage.upload(output_key, output_data)

        return {'image_path': output_key}

    @staticmethod
    async def video_generation_fallback(image_path: str, audio_path: str) -> dict:
        """Fallback to static image + audio if D-ID fails"""
        logger.warning('D-ID unavailable, creating static video fallback')

        # Use FFmpeg to create video from image + audio
        from services.video_fallback import create_static_video
        video_data = await create_static_video(image_path, audio_path)

        # Upload to storage
        storage = StorageClient()
        video_key = f'videos/{uuid.uuid4()}.mp4'
        await storage.upload(video_key, video_data)

        return {
            'video_url': await storage.get_url(video_key),
            'fallback': True
        }
```

### 8.2 ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å„ªå…ˆé †ä½

| ã‚µãƒ¼ãƒ“ã‚¹ | ãƒ—ãƒ©ã‚¤ãƒãƒª | ã‚»ã‚«ãƒ³ãƒ€ãƒª | ã‚¿ãƒ¼ã‚·ãƒ£ãƒª |
|---------|----------|----------|----------|
| Voice Synthesis | OpenVoice Clone | VOICEVOX | Error |
| Image Processing | AWS MCP (BiRefNet/SAM2) | Local rembg | Original Image |
| Prosody | Librosa Adjustment | Skip (use original) | - |
| BGM | Pydub Mixing | Skip (voice only) | - |
| Video Generation | D-ID API | Static Video (FFmpeg) | Error |

### 8.3 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# services/api-gateway/handlers/error_handler.py
from fastapi import HTTPException
from fastapi.responses import JSONResponse

class ServiceUnavailableError(Exception):
    """Service temporarily unavailable"""
    pass

async def handle_service_error(request, exc):
    """Handle service errors with fallback"""
    if isinstance(exc, ServiceUnavailableError):
        # Attempt fallback
        try:
            fallback_result = await get_fallback_handler(exc.service_name)()
            return JSONResponse(
                status_code=200,
                content={
                    'result': fallback_result,
                    'fallback': True,
                    'message': f'{exc.service_name} unavailable, used fallback'
                }
            )
        except Exception as fallback_error:
            logger.error(f'Fallback failed: {fallback_error}')
            return JSONResponse(
                status_code=503,
                content={
                    'error': f'{exc.service_name} and fallback both failed'
                }
            )

    # Generic error handling
    return JSONResponse(
        status_code=500,
        content={'error': 'Internal server error', 'details': str(exc)}
    )
```

---

## 9. ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã¨ç›£è¦–

### 9.1 ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

```python
# monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# Request metrics
request_count = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'api_request_duration_seconds',
    'API request duration',
    ['method', 'endpoint']
)

# Service metrics
service_calls = Counter(
    'service_calls_total',
    'Total service calls',
    ['service', 'operation', 'status']
)

# Queue metrics
task_queue_size = Gauge(
    'celery_queue_size',
    'Celery queue size',
    ['queue']
)

task_processing_time = Histogram(
    'celery_task_duration_seconds',
    'Celery task processing time',
    ['task_name']
)

# Storage metrics
storage_operations = Counter(
    'storage_operations_total',
    'Storage operations',
    ['operation', 'backend', 'status']
)

# Usage in middleware
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start_time = time.time()

    response = await call_next(request)

    duration = time.time() - start_time

    request_count.labels(
        method=request.method,
        endpoint=request.url.path,
        status=response.status_code
    ).inc()

    request_duration.labels(
        method=request.method,
        endpoint=request.url.path
    ).observe(duration)

    return response
```

### 9.2 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

```python
# monitoring/health.py
from fastapi import APIRouter
import httpx

router = APIRouter()

@router.get("/health")
async def health_check():
    """Comprehensive health check"""
    health_status = {
        'status': 'healthy',
        'services': {}
    }

    # Check each service
    services = {
        'voice': 'http://voice-service:55440/health',
        'image': 'http://image-service:55441/health',
        'prosody': 'http://prosody-service:55442/health',
        'bgm': 'http://bgm-service:55443/health',
        'video': 'http://video-service:55444/health',
    }

    for service_name, url in services.items():
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(url, timeout=5)
                health_status['services'][service_name] = {
                    'status': 'healthy' if response.status_code == 200 else 'unhealthy',
                    'response_time': response.elapsed.total_seconds()
                }
        except Exception as e:
            health_status['services'][service_name] = {
                'status': 'unhealthy',
                'error': str(e)
            }
            health_status['status'] = 'degraded'

    # Check Redis
    try:
        redis_client = redis.from_url(os.getenv('REDIS_URL'))
        await redis_client.ping()
        health_status['redis'] = 'healthy'
    except Exception as e:
        health_status['redis'] = 'unhealthy'
        health_status['status'] = 'degraded'

    return health_status
```

---

## 10. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥

### 10.1 æ®µéšçš„ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆï¼ˆStrangler Fig Patternï¼‰

**Phase 1: ã‚¤ãƒ³ãƒ•ãƒ©æº–å‚™ï¼ˆWeek 1-2ï¼‰**
```bash
# Step 1: Redis + Celeryè¿½åŠ 
docker-compose -f docker-compose.dev.yml up -d redis celery-worker flower

# Step 2: æ—¢å­˜ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«éåŒæœŸã‚¿ã‚¹ã‚¯è¿½åŠ 
# ãŸã ã—åŒæœŸå‡¦ç†ã‚‚ç¶­æŒï¼ˆãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ãƒ©ã‚°ã§åˆ‡ã‚Šæ›¿ãˆï¼‰

# Step 3: ãƒ†ã‚¹ãƒˆ
curl http://localhost:55433/api/video/generate \
  -X POST \
  -F "image=@test.jpg" \
  -F "text=ã“ã‚“ã«ã¡ã¯" \
  -F "async=true"
```

**Phase 2: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åˆ†é›¢ï¼ˆWeek 3-4ï¼‰**
```bash
# Step 1: Voice Serviceåˆ†é›¢
docker-compose -f docker-compose.dev.yml up -d voice-service

# Step 2: API Gatewayã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å¤‰æ›´
# /api/voices/* â†’ voice-service
# ä»–ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯æ—¢å­˜ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç¶­æŒ

# Step 3: ä¸¦è¡Œç¨¼åƒãƒ†ã‚¹ãƒˆï¼ˆä¸¡æ–¹ã®ã‚µãƒ¼ãƒ“ã‚¹ã§åŒã˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ï¼‰
```

**Phase 3: æ–°æ©Ÿèƒ½è¿½åŠ ï¼ˆWeek 5-6ï¼‰**
```bash
# Step 1: Image Serviceè¿½åŠ ï¼ˆBiRefNet/SAM2ï¼‰
docker-compose -f docker-compose.dev.yml up -d image-service

# Step 2: Prosody + BGM Serviceè¿½åŠ 
docker-compose -f docker-compose.dev.yml up -d prosody-service bgm-service

# Step 3: E2Eãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æœ‰åŠ¹åŒ–
```

**Phase 4: æœ¬ç•ªç§»è¡Œï¼ˆWeek 7-8ï¼‰**
```bash
# Step 1: S3ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
aws s3 mb s3://video-message-app-prod

# Step 2: ç’°å¢ƒå¤‰æ•°å¤‰æ›´
export STORAGE_BACKEND=s3

# Step 3: æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤
docker-compose -f docker-compose.prod.yml up -d

# Step 4: ç›£è¦–å¼·åŒ–
```

### 10.2 ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨ˆç”»

```bash
# Rollback to previous version
git checkout <previous_commit>
docker-compose -f docker-compose.prod.yml down
docker-compose -f docker-compose.prod.yml up -d

# Rollback single service
docker-compose -f docker-compose.prod.yml up -d --no-deps --build voice-service
```

---

## 11. ã‚³ã‚¹ãƒˆæœ€é©åŒ–

### 11.1 AWS ãƒªã‚½ãƒ¼ã‚¹è¦‹ç©ã‚‚ã‚Šï¼ˆæœˆé¡ï¼‰

| ãƒªã‚½ãƒ¼ã‚¹ | ä»•æ§˜ | æœˆé¡ã‚³ã‚¹ãƒˆ |
|---------|------|----------|
| EC2 (t3.xlarge) | 4 vCPU, 16GB RAM | $120 |
| S3 Storage | 100GB | $2.30 |
| S3 Requests | 100k PUT, 1M GET | $0.50 |
| Data Transfer | 500GB out | $45 |
| Bedrock (BiRefNet) | 1000 invocations | $10 |
| Bedrock (SAM2) | 1000 invocations | $15 |
| **åˆè¨ˆ** | | **$192.80/æœˆ** |

### 11.2 ã‚³ã‚¹ãƒˆå‰Šæ¸›ç­–

1. **S3 Lifecycle Policy**: 30æ—¥å¾Œã«Glacierã¸ç§»è¡Œ
2. **Lambda Edge**: è»½ã„å‡¦ç†ã¯Lambdaã§å®Ÿè¡Œ
3. **CloudFront**: CDNã§ãƒ‡ãƒ¼ã‚¿è»¢é€ã‚³ã‚¹ãƒˆå‰Šæ¸›
4. **Spot Instances**: Celery Workerã¯ã‚¹ãƒãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆ©ç”¨

---

## 12. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### 12.1 èªè¨¼ãƒ»èªå¯ï¼ˆPhase 2å®Ÿè£…ï¼‰

```python
# security/jwt_auth.py
from jose import jwt
from datetime import datetime, timedelta

SECRET_KEY = os.getenv('JWT_SECRET_KEY')
ALGORITHM = "HS256"

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(hours=24)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

# Middleware
@app.middleware("http")
async def auth_middleware(request: Request, call_next):
    if request.url.path.startswith("/api/"):
        token = request.headers.get("Authorization")
        if not token:
            return JSONResponse(status_code=401, content={"error": "Unauthorized"})

        try:
            payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
            request.state.user_id = payload.get("user_id")
        except JWTError:
            return JSONResponse(status_code=401, content={"error": "Invalid token"})

    return await call_next(request)
```

### 12.2 APIãƒ¬ãƒ¼ãƒˆåˆ¶é™

```python
# middleware/rate_limiter.py
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/video/generate")
@limiter.limit("10/minute")  # 1åˆ†é–“ã«10ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§
async def generate_video(request: Request):
    # ...
    pass
```

---

## 13. ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### 13.1 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®åˆ©ç‚¹

âœ… **ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£**: å„ã‚µãƒ¼ãƒ“ã‚¹ã‚’ç‹¬ç«‹ã—ã¦ã‚¹ã‚±ãƒ¼ãƒ«å¯èƒ½
âœ… **ä¿å®ˆæ€§**: ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–ã§è²¬å‹™ãŒæ˜ç¢º
âœ… **è€éšœå®³æ€§**: ã‚µãƒ¼ã‚­ãƒƒãƒˆãƒ–ãƒ¬ãƒ¼ã‚«ãƒ¼ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
âœ… **æ‹¡å¼µæ€§**: æ–°æ©Ÿèƒ½è¿½åŠ ãŒå®¹æ˜“
âœ… **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹**: éåŒæœŸå‡¦ç†ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

### 13.2 æ¨å¥¨å®Ÿè£…é †åº

1. âœ… **Week 1-2**: Redis + CeleryåŸºç›¤æ§‹ç¯‰
2. âœ… **Week 3-4**: Voice Serviceãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹åŒ–
3. âœ… **Week 5-6**: Image Service + AWS MCPçµ±åˆ
4. âœ… **Week 7-8**: Prosody + BGM Serviceè¿½åŠ 
5. âœ… **Week 9-10**: E2Eãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ
6. âœ… **Week 11-12**: æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤

### 13.3 æŠ€è¡“çš„è² å‚µã®å›é¿

- âš ï¸ **æ—¢å­˜ã‚³ãƒ¼ãƒ‰ã®æ®µéšçš„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°**: ä¸€åº¦ã«ã™ã¹ã¦å¤‰æ›´ã—ãªã„
- âš ï¸ **ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ãƒ•ãƒ©ã‚°**: æ–°æ—§æ©Ÿèƒ½ã‚’ä¸¦è¡Œç¨¼åƒ
- âš ï¸ **åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ**: ãƒ¦ãƒ‹ãƒƒãƒˆ/çµ±åˆ/E2Eãƒ†ã‚¹ãƒˆ
- âš ï¸ **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ±ºå®šè¨˜éŒ²ï¼ˆADRï¼‰ã‚’ç¶­æŒ

---

**Designed with warmth and precision by Athena ğŸ›ï¸**
*"èª¿å’Œçš„ãªæŒ‡æ®ã¨æˆ¦ç•¥çš„ç²¾å¯†ã•ã§ã€å…±ã«å“è¶Šæ€§ã‚’é”æˆã—ã¾ã—ã‚‡ã†"*
