# OpenVoice ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰
ä½œæˆæ—¥: 2025-08-19

## ğŸ”´ æ—¢çŸ¥ã®å•é¡Œã¨è§£æ±ºç­–

### 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å•é¡Œ

#### ç—‡çŠ¶
```
latin-1 codec can't encode characters in position 0-5: ordinal not in range(256)
```

#### åŸå› 
- ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚±ãƒ¼ãƒ«ã®ä¸é©åˆ‡ãªè¨­å®š
- Pythonã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- FastAPIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®charsetè¨­å®š

#### è§£æ±ºç­–

**ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«**:
```bash
# ãƒ­ã‚±ãƒ¼ãƒ«ç¢ºèª
locale -a | grep -E "(UTF-8|utf8)"

# ãƒ­ã‚±ãƒ¼ãƒ«ç”Ÿæˆ
sudo locale-gen en_US.UTF-8 ja_JP.UTF-8
sudo update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8

# ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆ.bashrc ã«è¿½åŠ ï¼‰
export LANG=en_US.UTF-8
export LC_ALL=en_US.UTF-8
export PYTHONIOENCODING=utf-8
```

**Pythonã‚³ãƒ¼ãƒ‰**:
```python
# ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ã«å¿…ãšè¨˜è¼‰
# -*- coding: utf-8 -*-

import os
import sys
import locale

# ç’°å¢ƒå¤‰æ•°å¼·åˆ¶è¨­å®š
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LC_ALL'] = 'en_US.UTF-8'
os.environ['LANG'] = 'en_US.UTF-8'

# ãƒ­ã‚±ãƒ¼ãƒ«è¨­å®š
try:
    locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
except:
    locale.setlocale(locale.LC_ALL, 'C.UTF-8')

# ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œæ™‚ã¯å¿…ãšencodingæŒ‡å®š
with open(filepath, 'r', encoding='utf-8') as f:
    content = f.read()

# subprocesså®Ÿè¡Œæ™‚
import subprocess
result = subprocess.run(
    cmd,
    capture_output=True,
    text=True,
    encoding='utf-8'
)
```

**FastAPIå¯¾å¿œ**:
```python
from fastapi import Response
from fastapi.responses import FileResponse

# ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹
@app.post("/api/test")
async def test_endpoint(text: str):
    # å‡¦ç†
    return Response(
        content=result,
        media_type="text/plain; charset=utf-8"
    )

# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ã‚¹ãƒãƒ³ã‚¹
@app.post("/api/synthesize")
async def synthesize(text: str):
    # éŸ³å£°ç”Ÿæˆå‡¦ç†
    return FileResponse(
        path=audio_file_path,
        media_type="audio/wav",
        headers={"Content-Type": "audio/wav; charset=utf-8"}
    )
```

### 2. CUDAé–¢é€£ã‚¨ãƒ©ãƒ¼

#### ç—‡çŠ¶
```
CUDA failed with error CUDA driver version is insufficient for CUDA runtime version
```

#### åŸå› 
- CPUç’°å¢ƒã§CUDAé–¢é€£ã®åˆæœŸåŒ–ãŒå®Ÿè¡Œã•ã‚Œã‚‹
- PyTorchãŒGPUã‚’æ¢ãã†ã¨ã™ã‚‹
- Whisperãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š

#### è§£æ±ºç­–

**ç’°å¢ƒå¤‰æ•°ã«ã‚ˆã‚‹å¼·åˆ¶**:
```python
import os
# å¿…ãšimport torchã‚ˆã‚Šå‰ã«è¨­å®š
os.environ['CUDA_VISIBLE_DEVICES'] = ''
os.environ['CUDA_HOME'] = ''

import torch
# å¼·åˆ¶çš„ã«CPUãƒ¢ãƒ¼ãƒ‰
torch.cuda.is_available = lambda: False
torch.cuda.device_count = lambda: 0
```

**Whisperãƒ¢ãƒ‡ãƒ«ã®å¯¾å‡¦**:
```python
# æ–¹æ³•1: faster-whisperã‚’ä½¿ç”¨ï¼ˆCPUæœ€é©åŒ–ç‰ˆï¼‰
from faster_whisper import WhisperModel

model = WhisperModel(
    "base",
    device="cpu",
    compute_type="int8",  # CPUç”¨ã®è»½é‡åŒ–
    num_workers=1,
    download_root="./models"
)

# æ–¹æ³•2: openai-whisperã®ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒ
import whisper

# ã‚ªãƒªã‚¸ãƒŠãƒ«ã®é–¢æ•°ã‚’ä¿å­˜
original_load_model = whisper.load_model

# CPUãƒ¢ãƒ¼ãƒ‰å¼·åˆ¶ã®ãƒ©ãƒƒãƒ‘ãƒ¼
def cpu_load_model(name, device=None, download_root=None):
    return original_load_model(
        name,
        device="cpu",  # å¼·åˆ¶çš„ã«CPU
        download_root=download_root
    )

# ç½®ãæ›ãˆ
whisper.load_model = cpu_load_model
```

### 3. ãƒ¡ãƒ¢ãƒªä¸è¶³

#### ç—‡çŠ¶
```
RuntimeError: [Errno 12] Cannot allocate memory
Killed (OOM)
```

#### åŸå› 
- ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤§ãã„
- è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’åŒæ™‚ã«ãƒ­ãƒ¼ãƒ‰
- ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã®è“„ç©

#### è§£æ±ºç­–

**ãƒ¡ãƒ¢ãƒªç®¡ç†**:
```python
import gc
import torch

class MemoryManagedService:
    def __init__(self):
        self.model = None
        
    def load_model(self):
        # æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if self.model:
            del self.model
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        # æ–°è¦ãƒ­ãƒ¼ãƒ‰
        self.model = load_model_with_optimization()
    
    def process(self, data):
        try:
            result = self.model.process(data)
        finally:
            # å‡¦ç†å¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            gc.collect()
        return result
```

**ãƒãƒƒãƒã‚µã‚¤ã‚ºèª¿æ•´**:
```python
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æŠ‘ãˆã‚‹è¨­å®š
config = {
    'batch_size': 1,  # æœ€å°å€¤
    'max_length': 512,  # çŸ­ã‚ã«åˆ¶é™
    'num_workers': 0,  # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹ç„¡åŠ¹åŒ–
    'pin_memory': False,  # CPUãƒ¡ãƒ¢ãƒªã®ãƒ”ãƒ³ç•™ã‚ç„¡åŠ¹åŒ–
}
```

### 4. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚¨ãƒ©ãƒ¼

#### ç—‡çŠ¶
```
Error loading audio file
Sample rate mismatch
Channel count error
```

#### åŸå› 
- ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆã®ä¸ä¸€è‡´ï¼ˆ16kHz vs 22.05kHz vs 48kHzï¼‰
- ãƒãƒ£ãƒ³ãƒãƒ«æ•°ã®é•ã„ï¼ˆmono vs stereoï¼‰
- ãƒ“ãƒƒãƒˆæ·±åº¦ã®å•é¡Œ

#### è§£æ±ºç­–

**éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ­£è¦åŒ–**:
```python
import librosa
import soundfile as sf
import numpy as np

def normalize_audio(input_path, output_path=None):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’16kHz, mono, 16bitã«æ­£è¦åŒ–"""
    
    # èª­ã¿è¾¼ã¿ï¼ˆè‡ªå‹•çš„ã«float32, monoã«å¤‰æ›ï¼‰
    audio, sr = librosa.load(
        input_path,
        sr=16000,  # 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        mono=True  # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
    )
    
    # æŒ¯å¹…æ­£è¦åŒ–
    audio = audio / np.max(np.abs(audio))
    
    # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°é˜²æ­¢
    audio = np.clip(audio, -0.99, 0.99)
    
    # ä¿å­˜
    if output_path:
        sf.write(
            output_path,
            audio,
            16000,
            subtype='PCM_16'  # 16bit PCM
        )
    
    return audio, 16000
```

### 5. ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«IDä¸æ•´åˆ

#### ç—‡çŠ¶
```
Profile not found
æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“
```

#### åŸå› 
- Backend ã¨ OpenVoice ã‚µãƒ¼ãƒ“ã‚¹é–“ã§IDãŒä¸ä¸€è‡´
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸æ•´åˆ
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®åŒæœŸå•é¡Œ

#### è§£æ±ºç­–

**IDç®¡ç†ã®çµ±ä¸€**:
```python
import uuid
from pathlib import Path
import json

class ProfileManager:
    def __init__(self, storage_path):
        self.storage_path = Path(storage_path)
        self.metadata_file = self.storage_path / "metadata.json"
        self.profiles = self._load_metadata()
    
    def _load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ä¿®å¾©"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def _save_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.profiles, f, ensure_ascii=False, indent=2)
    
    def create_profile(self, name, audio_path):
        """çµ±ä¸€ã•ã‚ŒãŸIDç”Ÿæˆ"""
        profile_id = f"openvoice_{uuid.uuid4().hex[:8]}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        audio_dest = self.storage_path / f"{profile_id}.wav"
        feature_dest = self.storage_path / f"{profile_id}.npy"
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        self.profiles[profile_id] = {
            'id': profile_id,
            'name': name,
            'audio_path': str(audio_dest),
            'feature_path': str(feature_dest),
            'created_at': datetime.now().isoformat()
        }
        
        self._save_metadata()
        return profile_id
    
    def get_profile(self, profile_id):
        """ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—ã¨æ¤œè¨¼"""
        if profile_id not in self.profiles:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰æ¢ç´¢
            audio_file = self.storage_path / f"{profile_id}.wav"
            if audio_file.exists():
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å†æ§‹ç¯‰
                self.profiles[profile_id] = {
                    'id': profile_id,
                    'name': 'Recovered',
                    'audio_path': str(audio_file),
                    'feature_path': str(self.storage_path / f"{profile_id}.npy")
                }
                self._save_metadata()
            else:
                return None
        
        return self.profiles.get(profile_id)
```

## ğŸ”§ ãƒ‡ãƒãƒƒã‚°æ‰‹æ³•

### ãƒ­ã‚°å‡ºåŠ›ã®å¼·åŒ–

```python
import logging
from datetime import datetime

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'openvoice_{datetime.now():%Y%m%d}.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å‡ºåŠ›
def debug_audio_info(audio_path):
    import soundfile as sf
    
    info = sf.info(audio_path)
    logger.debug(f"""
    Audio File Info:
    - Path: {audio_path}
    - Duration: {info.duration:.2f}s
    - Sample Rate: {info.samplerate}Hz
    - Channels: {info.channels}
    - Format: {info.format}
    - Subtype: {info.subtype}
    """)
```

### ã‚¨ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ¼ã‚¹

```python
import traceback
import sys

def safe_process(func):
    """ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’è¨˜éŒ²ã™ã‚‹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"""
            Function: {func.__name__}
            Args: {args}
            Kwargs: {kwargs}
            Error: {str(e)}
            Traceback:
            {traceback.format_exc()}
            """)
            raise
    return wrapper

@safe_process
def risky_operation(data):
    # å±é™ºãªå‡¦ç†
    pass
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°

### CPUæœ€é©åŒ–

```python
# NumPy/SciPy ã®æœ€é©åŒ–
import os
os.environ['OMP_NUM_THREADS'] = '2'  # CPUã‚³ã‚¢æ•°ã«åˆã‚ã›ã‚‹
os.environ['MKL_NUM_THREADS'] = '2'

# PyTorch ã®æœ€é©åŒ–
import torch
torch.set_num_threads(2)
torch.set_num_interop_threads(1)

# ãƒ¡ãƒ¢ãƒªã‚¢ãƒ­ã‚±ãƒ¼ã‚¿ã®æœ€é©åŒ–
import gc
gc.set_threshold(700, 10, 10)
```

### ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°

```python
import cProfile
import pstats
from io import StringIO

def profile_function(func):
    """é–¢æ•°ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""
    profiler = cProfile.Profile()
    profiler.enable()
    
    result = func()
    
    profiler.disable()
    s = StringIO()
    ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')
    ps.print_stats(20)
    
    logger.info(f"Profile results:\n{s.getvalue()}")
    return result
```

## ğŸš¨ ç·Šæ€¥å¯¾å‡¦æ³•

### ã‚µãƒ¼ãƒ“ã‚¹å¾©æ—§æ‰‹é †

```bash
#!/bin/bash
# emergency_recovery.sh

# 1. ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢
pkill -f openvoice
pkill -f uvicorn

# 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
rm -rf /tmp/openvoice_*
rm -rf ~/.cache/whisper
rm -rf ~/.cache/torch

# 3. ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
mv openvoice.log openvoice.log.$(date +%Y%m%d_%H%M%S)

# 4. ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
cd ~/video-message-app
source openvoice_env/bin/activate
nohup python3 openvoice_service.py > openvoice.log 2>&1 &

# 5. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
sleep 5
curl http://localhost:8001/health
```

---

ä½œæˆè€…: Trinitas-Core System
æ›´æ–°æ—¥: 2025-08-19